

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  <title>训练线性模型 - Hexo</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.4.0/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.7","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":2},"lazyload":{"enable":true,"onlypost":false},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}}};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.3.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>windilycloud</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="训练线性模型">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2019-04-09 00:00" pubdate>
        2019年4月9日 凌晨
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      4.4k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      84
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">训练线性模型</h1>
            
            <div class="markdown-body">
              <h2 id="用正规方程进行线性回归"><a href="#用正规方程进行线性回归" class="headerlink" title="用正规方程进行线性回归"></a>用正规方程进行线性回归</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>%matplotlib inline<br><span class="hljs-keyword">import</span> matplotlib<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>X = <span class="hljs-number">2</span>*np.random.rand(<span class="hljs-number">100</span>, <span class="hljs-number">1</span>)  <span class="hljs-comment">#单纯的生成2*（0——1）的随机数，规模为100*1</span><br>y = <span class="hljs-number">4</span> + <span class="hljs-number">3</span> * X + np.random.randn(<span class="hljs-number">100</span>, <span class="hljs-number">1</span>) <span class="hljs-comment">#randn服从标准正态分布</span><br>plt.plot(X, y, <span class="hljs-string">&quot;b.&quot;</span>)<br>plt.xlabel(<span class="hljs-string">&quot;$x_1$&quot;</span>, fontsize=<span class="hljs-number">18</span>)<br>plt.ylabel(<span class="hljs-string">&quot;$y$&quot;</span>, rotation=<span class="hljs-number">0</span>, fontsize=<span class="hljs-number">18</span>)<br>plt.axis([<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">15</span>])<br>plt.show()<br></code></pre></td></tr></table></figure>

<p><img src="%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%5Coutput_1_0.png" srcset="/img/loading.gif" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">X_b = np.c_[np.ones((<span class="hljs-number">100</span>,<span class="hljs-number">1</span>)), X] <span class="hljs-comment">#添加一列全1列在X左边,不添的话回归方程则没有偏置项</span><br>theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)<br>theta_best<br></code></pre></td></tr></table></figure>



<pre><code>array([[ 4.0224133],
       [ 3.0375984]])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">X_new = np.array([[<span class="hljs-number">0</span>],[<span class="hljs-number">2</span>]])<br>X_new_b = np.c_[np.ones((<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)),X_new]  <span class="hljs-comment">#这才是实例的向量形式</span><br>y_predict = X_new_b.dot(theta_best)<br>y_predict<br></code></pre></td></tr></table></figure>



<pre><code>array([[  4.0224133 ],
       [ 10.09761009]])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.plot(X, y, <span class="hljs-string">&quot;b.&quot;</span>)<br>plt.xlabel(<span class="hljs-string">&quot;$x_1$&quot;</span>, fontsize=<span class="hljs-number">18</span>)<br>plt.ylabel(<span class="hljs-string">&quot;$y$&quot;</span>, rotation=<span class="hljs-number">0</span>, fontsize=<span class="hljs-number">18</span>)<br>plt.axis([<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">15</span>])<br>plt.plot(X_new, y_predict,<span class="hljs-string">&quot;r-&quot;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>

<p><img src="%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%5Coutput_4_1.png" srcset="/img/loading.gif" alt="png"></p>
<h2 id="用模型进行线性回归"><a href="#用模型进行线性回归" class="headerlink" title="用模型进行线性回归"></a>用模型进行线性回归</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression<br><br>lin_reg = LinearRegression()<br>lin_reg.fit(X,y)<br>lin_reg.intercept_,lin_reg.coef_  <span class="hljs-comment">#intercept截距，coef系数</span><br></code></pre></td></tr></table></figure>



<pre><code>(array([ 4.0224133]), array([[ 3.0375984]]))</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">lin_reg.predict(X_new) <span class="hljs-comment">#预测得和正规方程一样，不过这是基于SVD矩阵分解的</span><br></code></pre></td></tr></table></figure>



<pre><code>array([[  4.0224133 ],
       [ 10.09761009]])</code></pre>
<h2 id="用批量梯度下降进行线性回归"><a href="#用批量梯度下降进行线性回归" class="headerlink" title="用批量梯度下降进行线性回归"></a>用批量梯度下降进行线性回归</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">eta = <span class="hljs-number">0.1</span> <span class="hljs-comment">#study rate</span><br>n_iterations = <span class="hljs-number">10000</span><br>m = <span class="hljs-number">100</span> <span class="hljs-comment">#the number of train example</span><br>theta = np.random.randn(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>) <span class="hljs-comment">#随机初始值</span><br><br><span class="hljs-keyword">for</span> iteration <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_iterations):<br>    gradients = <span class="hljs-number">2</span>/m * X_b.T.dot(X_b.dot(theta) -y)  <span class="hljs-comment">#均方误差的偏导数</span><br>    theta = theta - eta * gradients<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">theta <span class="hljs-comment">#最后得到theta的优化值</span><br></code></pre></td></tr></table></figure>



<pre><code>array([[ 4.0224133],
       [ 3.0375984]])</code></pre>
<h3 id="探索批量梯度下降"><a href="#探索批量梯度下降" class="headerlink" title="探索批量梯度下降"></a>探索批量梯度下降</h3><p><strong>过程</strong></p>
<ol>
<li>随机选取一个theta</li>
<li>用整个训练集求出一个固定的梯度</li>
<li>递归优化theta</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">theta_path_bgd = []   <span class="hljs-comment">#存储theta的过程值</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_gradient_descent</span>(<span class="hljs-params">theta, eta, theta_path = <span class="hljs-literal">None</span></span>):</span><br>    m = <span class="hljs-built_in">len</span>(X_b)<br>    plt.plot(X, y, <span class="hljs-string">&quot;b.&quot;</span>)<br>    n_iterations = <span class="hljs-number">1000</span><br>    <span class="hljs-keyword">for</span> iteration <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_iterations):<br>        <span class="hljs-keyword">if</span> iteration &lt; <span class="hljs-number">10</span>:<br>            y_predict = X_new_b.dot(theta)<br>            style = <span class="hljs-string">&quot;b-&quot;</span> <span class="hljs-keyword">if</span> iteration &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;r--&quot;</span><br>            plt.plot(X_new, y_predict, style)<br>        gradients = <span class="hljs-number">2</span>/m * X_b.T.dot(X_b.dot(theta) - y)<br>        theta = theta - eta * gradients<br>        <span class="hljs-keyword">if</span> theta_path <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            theta_path.append(theta)<br>    plt.xlabel(<span class="hljs-string">&quot;$X_1$&quot;</span>, fontsize = <span class="hljs-number">18</span>)<br>    plt.axis([<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>,<span class="hljs-number">15</span>])<br>    plt.title(<span class="hljs-string">r&quot;$\eta$ = &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(eta), fontsize = <span class="hljs-number">16</span>)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">np.random.seed(<span class="hljs-number">42</span>)<br>theta = np.random.randn(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)<br><br>plt.figure(figsize=(<span class="hljs-number">10</span>,<span class="hljs-number">4</span>))<br>plt.subplot(<span class="hljs-number">131</span>); plot_gradient_descent(theta, eta=<span class="hljs-number">0.02</span>)<br>plt.ylabel(<span class="hljs-string">&quot;$y$&quot;</span>, rotation=<span class="hljs-number">0</span>, fontsize=<span class="hljs-number">18</span>)<br>plt.subplot(<span class="hljs-number">132</span>); plot_gradient_descent(theta, eta=<span class="hljs-number">0.1</span>, theta_path=theta_path_bgd)<br>plt.subplot(<span class="hljs-number">133</span>); plot_gradient_descent(theta, eta=<span class="hljs-number">0.5</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>

<p><img src="%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%5Coutput_14_0.png" srcset="/img/loading.gif" alt="png"></p>
<pre><code>[array([[ 1.86730689],
       [ 1.50575404]]), array([[ 2.61930247],
       [ 2.39396727]]), array([[ 3.03478759],
      .......</code></pre>
<p>表明学习率$\eta$太低，迭代次数过高且速度缓慢，太高会越偏越远，一致无法达到MSE的最小值</p>
<h2 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h2><p><strong>过程</strong></p>
<ol>
<li>随机选个theta</li>
<li>在训练集中随机选一个点求出其梯度</li>
<li>随着迭代次数增加降低学习率</li>
<li>递归优化theta</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python">theta_path_sgd = []<br>m = <span class="hljs-built_in">len</span>(X_b)<br>np.random.seed(<span class="hljs-number">42</span>)<br>n_epochs = <span class="hljs-number">50</span><br>t0, t1 = <span class="hljs-number">5</span>, <span class="hljs-number">50</span>  <span class="hljs-comment"># learning schedule hyperparameters</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">learning_schedule</span>(<span class="hljs-params">t</span>):</span><br>    <span class="hljs-keyword">return</span> t0 / (t + t1)<br><br>theta = np.random.randn(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)  <span class="hljs-comment"># random initialization</span><br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_epochs):<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(m):<br>        <span class="hljs-keyword">if</span> epoch &lt;<span class="hljs-number">50</span> <span class="hljs-keyword">and</span> i &lt; <span class="hljs-number">20</span>:                    <br>            y_predict = X_new_b.dot(theta)          <br>            style = <span class="hljs-string">&quot;b-&quot;</span> <span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;r--&quot;</span>        <br>            plt.plot(X_new, y_predict, style)       <br>    random_index = np.random.randint(m)<br>    xi = X_b[random_index:random_index+<span class="hljs-number">1</span>]<br>    yi = y[random_index:random_index+<span class="hljs-number">1</span>]<br>    gradients = <span class="hljs-number">2</span> * xi.T.dot(xi.dot(theta) - yi)    <span class="hljs-comment">#梯度是随机选一个点进行计算</span><br>    eta = learning_schedule(epoch + i)           <span class="hljs-comment">#学习率随着迭代次数增加而增加</span><br>    theta = theta - eta * gradients<br>    theta_path_sgd.append(theta)                 <br><br>plt.plot(X, y, <span class="hljs-string">&quot;b.&quot;</span>)                                 <br>plt.xlabel(<span class="hljs-string">&quot;$x_1$&quot;</span>, fontsize=<span class="hljs-number">18</span>)                    <br>plt.ylabel(<span class="hljs-string">&quot;$y$&quot;</span>, rotation=<span class="hljs-number">0</span>, fontsize=<span class="hljs-number">18</span>)          <br>plt.axis([<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">15</span>])                                <br>plt.show()           <span class="hljs-comment">#学习率过早减小导致下图</span><br></code></pre></td></tr></table></figure>

<p><img src="%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%5Coutput_18_0.png" srcset="/img/loading.gif" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">theta<br></code></pre></td></tr></table></figure>



<pre><code>array([[ 3.84494505],
       [ 3.27773445]])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> SGDRegressor<br>sgd_reg = SGDRegressor(max_iter=<span class="hljs-number">50</span>, penalty=<span class="hljs-literal">None</span>, eta0=<span class="hljs-number">0.1</span>, random_state=<span class="hljs-number">42</span>)<br>sgd_reg.fit(X, y.ravel())<br></code></pre></td></tr></table></figure>



<pre><code>SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,
       eta0=0.1, fit_intercept=True, l1_ratio=0.15,
       learning_rate=&#39;invscaling&#39;, loss=&#39;squared_loss&#39;, max_iter=50,
       n_iter=None, n_iter_no_change=5, penalty=None, power_t=0.25,
       random_state=42, shuffle=True, tol=None, validation_fraction=0.1,
       verbose=0, warm_start=False)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">sgd_reg.intercept_,sgd_reg.coef_<br></code></pre></td></tr></table></figure>



<pre><code>(array([ 4.15885372]), array([ 2.78382451]))</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">y.ravel()<br></code></pre></td></tr></table></figure>



<pre><code>array([  7.92135333,   8.56691098,   5.99502404,   5.41513681,
         6.44148562,   4.86811936,   7.10136485,   3.42339943,
         3.67839599,   3.33761007,  10.60499941,   9.85896324,
         5.24987976,   6.41309292,   8.27404813,  10.2284994 ,
         7.36249471,   5.53075467,   5.82242636,   8.73811634,
         7.71831938,   5.68942818,   5.53702494,   9.31348781,
         6.38312742,   4.65636541,   6.822189  ,   7.57527945,
         5.09018294,   8.20892064,   5.26167648,   9.31611915,
         8.25069641,   6.20716153,   4.74007077,   4.21154293,
         5.47356181,   3.65836925,   4.49619836,  10.47303379,
         4.04746793,   7.79850061,   5.65985419,   4.04421099,
         4.87118555,   9.47709443,   4.84031852,   3.17888951,
         8.07583515,   7.40261652,   5.9161954 ,   8.05550747,
         6.00742713,   7.663237  ,   7.18763962,   6.41589604,
         3.6484945 ,   7.5615348 ,   6.90866543,   4.66088275,
        11.41090766,   8.55184292,   4.54870059,   5.88453553,
         6.50245164,   8.94983926,   8.9836167 ,   7.81270696,
         4.19772038,   3.87984973,   5.78906629,   8.39476674,
         5.68339181,   8.74063201,   8.90028377,   5.26353559,
         5.56526364,   6.71891745,   9.75285961,   5.96614923,
         4.63267988,   8.25034491,   8.51859076,   4.67946486,
         8.49665663,   5.23937975,   4.98571677,   8.24719202,
         9.71403888,   8.88804298,   4.58339356,   9.07247433,
         6.27455895,   9.07438272,  10.39908052,   5.87060124,
         8.06497982,   4.13650819,   8.94576743,   8.60587748])</code></pre>
<h2 id="小批量梯度下降"><a href="#小批量梯度下降" class="headerlink" title="小批量梯度下降"></a>小批量梯度下降</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python">theta_path_mgd = []<br><br>n_iterations = <span class="hljs-number">50</span><br>minibatch_size = <span class="hljs-number">20</span><br><br>np.random.seed(<span class="hljs-number">42</span>)<br>theta = np.random.randn(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)  <span class="hljs-comment"># random initialization</span><br><br>t0, t1 = <span class="hljs-number">200</span>, <span class="hljs-number">1000</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">learning_schedule</span>(<span class="hljs-params">t</span>):</span><br>    <span class="hljs-keyword">return</span> t0 / (t + t1)<br><br>t = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_iterations):<br>    shuffled_indices = np.random.permutation(m)<br>    X_b_shuffled = X_b[shuffled_indices]<br>    y_shuffled = y[shuffled_indices]<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, m, minibatch_size):<br>        t += <span class="hljs-number">1</span><br>        xi = X_b_shuffled[i:i+minibatch_size]<br>        yi = y_shuffled[i:i+minibatch_size]<br>        gradients = <span class="hljs-number">2</span>/minibatch_size * xi.T.dot(xi.dot(theta) - yi)<br>        eta = learning_schedule(t)<br>        theta = theta - eta * gradients<br>        theta_path_mgd.append(theta)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">theta<br></code></pre></td></tr></table></figure>



<pre><code>array([[ 4.21526857],
       [ 2.81576239]])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">theta_path_bgd = np.array(theta_path_bgd)<br>theta_path_sgd = np.array(theta_path_sgd)<br>theta_path_mgd = np.array(theta_path_mgd)<br><br>plt.figure(figsize=(<span class="hljs-number">7</span>,<span class="hljs-number">4</span>))<br>plt.plot(theta_path_sgd[:, <span class="hljs-number">0</span>], theta_path_sgd[:, <span class="hljs-number">1</span>], <span class="hljs-string">&quot;r-s&quot;</span>, linewidth=<span class="hljs-number">1</span>, label=<span class="hljs-string">&quot;Stochastic&quot;</span>)<br>plt.plot(theta_path_mgd[:, <span class="hljs-number">0</span>], theta_path_mgd[:, <span class="hljs-number">1</span>], <span class="hljs-string">&quot;g-+&quot;</span>, linewidth=<span class="hljs-number">2</span>, label=<span class="hljs-string">&quot;Mini-batch&quot;</span>)<br>plt.plot(theta_path_bgd[:, <span class="hljs-number">0</span>], theta_path_bgd[:, <span class="hljs-number">1</span>], <span class="hljs-string">&quot;b-o&quot;</span>, linewidth=<span class="hljs-number">3</span>, label=<span class="hljs-string">&quot;Batch&quot;</span>)<br>plt.legend(loc=<span class="hljs-string">&quot;upper left&quot;</span>, fontsize=<span class="hljs-number">16</span>)<br>plt.xlabel(<span class="hljs-string">r&quot;$\theta_0$&quot;</span>, fontsize=<span class="hljs-number">20</span>)<br>plt.ylabel(<span class="hljs-string">r&quot;$\theta_1$   &quot;</span>, fontsize=<span class="hljs-number">20</span>, rotation=<span class="hljs-number">0</span>)<br>plt.axis([<span class="hljs-number">2.5</span>, <span class="hljs-number">4.5</span>, <span class="hljs-number">2.3</span>, <span class="hljs-number">3.9</span>])<br>plt.show()<br></code></pre></td></tr></table></figure>

<p><img src="%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%5Coutput_26_0.png" srcset="/img/loading.gif" alt="png"></p>
<h2 id="多项式回归"><a href="#多项式回归" class="headerlink" title="多项式回归"></a>多项式回归</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> numpy.random <span class="hljs-keyword">as</span> rnd<br>np.random.seed(<span class="hljs-number">42</span>)<br><br>m = <span class="hljs-number">100</span><br>X = <span class="hljs-number">6</span> * np.random.rand(m, <span class="hljs-number">1</span>) - <span class="hljs-number">3</span><br>y = <span class="hljs-number">0.5</span> * X**<span class="hljs-number">2</span> + X + <span class="hljs-number">2</span> + np.random.randn(m, <span class="hljs-number">1</span>)<br><br>plt.plot(X, y, <span class="hljs-string">&quot;b.&quot;</span>)<br>plt.xlabel(<span class="hljs-string">&quot;$x_1$&quot;</span>, fontsize=<span class="hljs-number">18</span>)<br>plt.ylabel(<span class="hljs-string">&quot;$y$&quot;</span>, rotation=<span class="hljs-number">0</span>, fontsize=<span class="hljs-number">18</span>)<br>plt.axis([-<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">10</span>])<br>plt.show()<br></code></pre></td></tr></table></figure>

<p><img src="%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%5Coutput_28_0.png" srcset="/img/loading.gif" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> PolynomialFeatures<br>poly_features = PolynomialFeatures(degree=<span class="hljs-number">2</span>, include_bias=<span class="hljs-literal">False</span>)<br>X_poly = poly_features.fit_transform(X)<br>X[<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure>



<pre><code>array([-0.75275929])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">X_poly[<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure>



<pre><code>array([-0.75275929,  0.56664654])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">lin_reg = LinearRegression()<br>lin_reg.fit(X_poly, y)<br>lin_reg.intercept_, lin_reg.coef_<br></code></pre></td></tr></table></figure>



<pre><code>(array([ 1.78134581]), array([[ 0.93366893,  0.56456263]]))</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">X_new=np.linspace(-<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">100</span>).reshape(<span class="hljs-number">100</span>, <span class="hljs-number">1</span>)<br>X_new_poly = poly_features.transform(X_new)<br>y_new = lin_reg.predict(X_new_poly)<br>plt.plot(X, y, <span class="hljs-string">&quot;b.&quot;</span>)<br>plt.plot(X_new, y_new, <span class="hljs-string">&quot;r-&quot;</span>, linewidth=<span class="hljs-number">2</span>, label=<span class="hljs-string">&quot;Predictions&quot;</span>)<br>plt.xlabel(<span class="hljs-string">&quot;$x_1$&quot;</span>, fontsize=<span class="hljs-number">18</span>)<br>plt.ylabel(<span class="hljs-string">&quot;$y$&quot;</span>, rotation=<span class="hljs-number">0</span>, fontsize=<span class="hljs-number">18</span>)<br>plt.legend(loc=<span class="hljs-string">&quot;upper left&quot;</span>, fontsize=<span class="hljs-number">14</span>)<br>plt.axis([-<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">10</span>])<br>plt.show()<br></code></pre></td></tr></table></figure>

<p><img src="%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%5Coutput_32_0.png" srcset="/img/loading.gif" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br><span class="hljs-keyword">from</span> sklearn.pipeline <span class="hljs-keyword">import</span> Pipeline<br><br><span class="hljs-keyword">for</span> style, width, degree <span class="hljs-keyword">in</span> ((<span class="hljs-string">&quot;g-&quot;</span>, <span class="hljs-number">1</span>, <span class="hljs-number">300</span>), (<span class="hljs-string">&quot;b--&quot;</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>), (<span class="hljs-string">&quot;r-+&quot;</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)):<br>    polybig_features = PolynomialFeatures(degree=degree, include_bias=<span class="hljs-literal">False</span>)<br>    std_scaler = StandardScaler()<br>    lin_reg = LinearRegression()<br>    polynomial_regression = Pipeline([<br>            (<span class="hljs-string">&quot;poly_features&quot;</span>, polybig_features),<br>            (<span class="hljs-string">&quot;std_scaler&quot;</span>, std_scaler),<br>            (<span class="hljs-string">&quot;lin_reg&quot;</span>, lin_reg),<br>        ])<br>    polynomial_regression.fit(X, y)<br>    y_newbig = polynomial_regression.predict(X_new)<br>    plt.plot(X_new, y_newbig, style, label=<span class="hljs-built_in">str</span>(degree), linewidth=width)<br><br>plt.plot(X, y, <span class="hljs-string">&quot;b.&quot;</span>, linewidth=<span class="hljs-number">3</span>)<br>plt.legend(loc=<span class="hljs-string">&quot;upper left&quot;</span>)<br>plt.xlabel(<span class="hljs-string">&quot;$x_1$&quot;</span>, fontsize=<span class="hljs-number">18</span>)<br>plt.ylabel(<span class="hljs-string">&quot;$y$&quot;</span>, rotation=<span class="hljs-number">0</span>, fontsize=<span class="hljs-number">18</span>)<br>plt.axis([-<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">10</span>])<br>plt.show()<br></code></pre></td></tr></table></figure>

<p><img src="%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%5Coutput_33_0.png" srcset="/img/loading.gif" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_learning_curves</span>(<span class="hljs-params">model, X, y</span>):</span><br>    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">10</span>)<br>    train_errors, val_errors = [], []<br>    <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(X_train)):<br>        model.fit(X_train[:m], y_train[:m])<br>        y_train_predict = model.predict(X_train[:m])<br>        y_val_predict = model.predict(X_val)<br>        train_errors.append(mean_squared_error(y_train[:m], y_train_predict))<br>        val_errors.append(mean_squared_error(y_val, y_val_predict))<br><br>    plt.plot(np.sqrt(train_errors), <span class="hljs-string">&quot;r-+&quot;</span>, linewidth=<span class="hljs-number">2</span>, label=<span class="hljs-string">&quot;train&quot;</span>)<br>    plt.plot(np.sqrt(val_errors), <span class="hljs-string">&quot;b-&quot;</span>, linewidth=<span class="hljs-number">3</span>, label=<span class="hljs-string">&quot;val&quot;</span>)<br>    plt.legend(loc=<span class="hljs-string">&quot;upper right&quot;</span>, fontsize=<span class="hljs-number">14</span>)   <span class="hljs-comment"># not shown in the book</span><br>    plt.xlabel(<span class="hljs-string">&quot;Training set size&quot;</span>, fontsize=<span class="hljs-number">14</span>) <span class="hljs-comment"># not shown</span><br>    plt.ylabel(<span class="hljs-string">&quot;RMSE&quot;</span>, fontsize=<span class="hljs-number">14</span>)              <span class="hljs-comment"># not shown</span><br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">lin_reg = LinearRegression()<br>plot_learning_curves(lin_reg, X, y)<br>plt.axis([<span class="hljs-number">0</span>, <span class="hljs-number">80</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>])                         <span class="hljs-comment"># not shown in the book</span><br>plt.show()                                      <span class="hljs-comment"># not shown</span><br></code></pre></td></tr></table></figure>

<p><img src="%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%5Coutput_35_0.png" srcset="/img/loading.gif" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.pipeline <span class="hljs-keyword">import</span> Pipeline<br><br>polynomial_regression = Pipeline([<br>        (<span class="hljs-string">&quot;poly_features&quot;</span>, PolynomialFeatures(degree=<span class="hljs-number">10</span>, include_bias=<span class="hljs-literal">False</span>)),<br>        (<span class="hljs-string">&quot;lin_reg&quot;</span>, LinearRegression()),<br>    ])<br><br>plot_learning_curves(polynomial_regression, X, y)<br>plt.axis([<span class="hljs-number">0</span>, <span class="hljs-number">80</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>])           <span class="hljs-comment"># not shown</span><br>plt.show()     <br></code></pre></td></tr></table></figure>

<p><img src="%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%5Coutput_36_0.png" srcset="/img/loading.gif" alt="png"></p>
<h2 id="正则化模型"><a href="#正则化模型" class="headerlink" title="正则化模型"></a>正则化模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> Ridge<br><br>np.random.seed(<span class="hljs-number">42</span>)<br>m = <span class="hljs-number">20</span><br>X = <span class="hljs-number">3</span> * np.random.rand(m, <span class="hljs-number">1</span>)<br>y = <span class="hljs-number">1</span> + <span class="hljs-number">0.5</span> * X + np.random.randn(m, <span class="hljs-number">1</span>) / <span class="hljs-number">1.5</span><br>X_new = np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">100</span>).reshape(<span class="hljs-number">100</span>, <span class="hljs-number">1</span>)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_model</span>(<span class="hljs-params">model_class, polynomial, alphas, **model_kargs</span>):</span><br>    <span class="hljs-keyword">for</span> alpha, style <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(alphas, (<span class="hljs-string">&quot;b-&quot;</span>, <span class="hljs-string">&quot;g--&quot;</span>, <span class="hljs-string">&quot;r:&quot;</span>)):<br>        model = model_class(alpha, **model_kargs) <span class="hljs-keyword">if</span> alpha &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> LinearRegression()<br>        <span class="hljs-keyword">if</span> polynomial:<br>            model = Pipeline([<br>                    (<span class="hljs-string">&quot;poly_features&quot;</span>, PolynomialFeatures(degree=<span class="hljs-number">10</span>, include_bias=<span class="hljs-literal">False</span>)),<br>                    (<span class="hljs-string">&quot;std_scaler&quot;</span>, StandardScaler()),<br>                    (<span class="hljs-string">&quot;regul_reg&quot;</span>, model),<br>                ])<br>        model.fit(X, y)<br>        y_new_regul = model.predict(X_new)<br>        lw = <span class="hljs-number">2</span> <span class="hljs-keyword">if</span> alpha &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">1</span><br>        plt.plot(X_new, y_new_regul, style, linewidth=lw, label=<span class="hljs-string">r&quot;$\alpha = &#123;&#125;$&quot;</span>.<span class="hljs-built_in">format</span>(alpha))<br>    plt.plot(X, y, <span class="hljs-string">&quot;b.&quot;</span>, linewidth=<span class="hljs-number">3</span>)<br>    plt.legend(loc=<span class="hljs-string">&quot;upper left&quot;</span>, fontsize=<span class="hljs-number">15</span>)<br>    plt.xlabel(<span class="hljs-string">&quot;$x_1$&quot;</span>, fontsize=<span class="hljs-number">18</span>)<br>    plt.axis([<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">4</span>])<br><br>plt.figure(figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">4</span>))<br>plt.subplot(<span class="hljs-number">121</span>)<br>plot_model(Ridge, polynomial=<span class="hljs-literal">False</span>, alphas=(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>, <span class="hljs-number">100</span>), random_state=<span class="hljs-number">42</span>)<br>plt.ylabel(<span class="hljs-string">&quot;$y$&quot;</span>, rotation=<span class="hljs-number">0</span>, fontsize=<span class="hljs-number">18</span>)<br>plt.subplot(<span class="hljs-number">122</span>)<br>plot_model(Ridge, polynomial=<span class="hljs-literal">True</span>, alphas=(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>**-<span class="hljs-number">5</span>, <span class="hljs-number">1</span>), random_state=<span class="hljs-number">42</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>

<p><img src="%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%5Coutput_38_0.png" srcset="/img/loading.gif" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> Ridge<br>ridge_reg = Ridge(alpha=<span class="hljs-number">1</span>, solver=<span class="hljs-string">&quot;cholesky&quot;</span>, random_state=<span class="hljs-number">42</span>)<br>ridge_reg.fit(X, y)<br>ridge_reg.predict([[<span class="hljs-number">1.5</span>]])<br></code></pre></td></tr></table></figure>



<pre><code>array([[ 1.55071465]])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">sgd_reg = SGDRegressor(max_iter=<span class="hljs-number">5</span>, penalty=<span class="hljs-string">&quot;l2&quot;</span>, random_state=<span class="hljs-number">42</span>)<br>sgd_reg.fit(X, y.ravel())<br>sgd_reg.predict([[<span class="hljs-number">1.5</span>]])<br></code></pre></td></tr></table></figure>



<pre><code>array([ 1.13500145])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">ridge_reg = Ridge(alpha=<span class="hljs-number">1</span>, solver=<span class="hljs-string">&quot;sag&quot;</span>, random_state=<span class="hljs-number">42</span>)<br>ridge_reg.fit(X, y)<br>ridge_reg.predict([[<span class="hljs-number">1.5</span>]])<br></code></pre></td></tr></table></figure>



<pre><code>array([[ 1.5507201]])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> Lasso<br><br>plt.figure(figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">4</span>))<br>plt.subplot(<span class="hljs-number">121</span>)<br>plot_model(Lasso, polynomial=<span class="hljs-literal">False</span>, alphas=(<span class="hljs-number">0</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>), random_state=<span class="hljs-number">42</span>)<br>plt.ylabel(<span class="hljs-string">&quot;$y$&quot;</span>, rotation=<span class="hljs-number">0</span>, fontsize=<span class="hljs-number">18</span>)<br>plt.subplot(<span class="hljs-number">122</span>)<br>plot_model(Lasso, polynomial=<span class="hljs-literal">True</span>, alphas=(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>**-<span class="hljs-number">7</span>, <span class="hljs-number">1</span>), tol=<span class="hljs-number">1</span>, random_state=<span class="hljs-number">42</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>

<p><img src="%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%5Coutput_42_0.png" srcset="/img/loading.gif" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> Lasso<br>lasso_reg = Lasso(alpha=<span class="hljs-number">0.1</span>)<br>lasso_reg.fit(X, y)<br>lasso_reg.predict([[<span class="hljs-number">1.5</span>]])<br></code></pre></td></tr></table></figure>



<pre><code>array([ 1.53788174])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> ElasticNet<br>elastic_net = ElasticNet(alpha=<span class="hljs-number">0.1</span>, l1_ratio=<span class="hljs-number">0.5</span>, random_state=<span class="hljs-number">42</span>)<br>elastic_net.fit(X, y)<br>elastic_net.predict([[<span class="hljs-number">1.5</span>]])<br></code></pre></td></tr></table></figure>



<pre><code>array([ 1.54333232])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs python">np.random.seed(<span class="hljs-number">42</span>)<br>m = <span class="hljs-number">100</span><br>X = <span class="hljs-number">6</span> * np.random.rand(m, <span class="hljs-number">1</span>) - <span class="hljs-number">3</span><br>y = <span class="hljs-number">2</span> + X + <span class="hljs-number">0.5</span> * X**<span class="hljs-number">2</span> + np.random.randn(m, <span class="hljs-number">1</span>)<br><br>X_train, X_val, y_train, y_val = train_test_split(X[:<span class="hljs-number">50</span>], y[:<span class="hljs-number">50</span>].ravel(), test_size=<span class="hljs-number">0.5</span>, random_state=<span class="hljs-number">10</span>)<br><br>poly_scaler = Pipeline([<br>        (<span class="hljs-string">&quot;poly_features&quot;</span>, PolynomialFeatures(degree=<span class="hljs-number">90</span>, include_bias=<span class="hljs-literal">False</span>)),<br>        (<span class="hljs-string">&quot;std_scaler&quot;</span>, StandardScaler()),<br>    ])<br><br>X_train_poly_scaled = poly_scaler.fit_transform(X_train)<br>X_val_poly_scaled = poly_scaler.transform(X_val)<br><br>sgd_reg = SGDRegressor(max_iter=<span class="hljs-number">1</span>,<br>                       penalty=<span class="hljs-literal">None</span>,<br>                       eta0=<span class="hljs-number">0.0005</span>,<br>                       warm_start=<span class="hljs-literal">True</span>,<br>                       learning_rate=<span class="hljs-string">&quot;constant&quot;</span>,<br>                       random_state=<span class="hljs-number">42</span>)<br><br>n_epochs = <span class="hljs-number">500</span><br>train_errors, val_errors = [], []<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_epochs):<br>    sgd_reg.fit(X_train_poly_scaled, y_train)<br>    y_train_predict = sgd_reg.predict(X_train_poly_scaled)<br>    y_val_predict = sgd_reg.predict(X_val_poly_scaled)<br>    train_errors.append(mean_squared_error(y_train, y_train_predict))<br>    val_errors.append(mean_squared_error(y_val, y_val_predict))<br><br>best_epoch = np.argmin(val_errors)<br>best_val_rmse = np.sqrt(val_errors[best_epoch])<br><br>plt.annotate(<span class="hljs-string">&#x27;Best model&#x27;</span>,<br>             xy=(best_epoch, best_val_rmse),<br>             xytext=(best_epoch, best_val_rmse + <span class="hljs-number">1</span>),<br>             ha=<span class="hljs-string">&quot;center&quot;</span>,<br>             arrowprops=<span class="hljs-built_in">dict</span>(facecolor=<span class="hljs-string">&#x27;black&#x27;</span>, shrink=<span class="hljs-number">0.05</span>),<br>             fontsize=<span class="hljs-number">16</span>,<br>            )<br><br>best_val_rmse -= <span class="hljs-number">0.03</span>  <span class="hljs-comment"># just to make the graph look better</span><br>plt.plot([<span class="hljs-number">0</span>, n_epochs], [best_val_rmse, best_val_rmse], <span class="hljs-string">&quot;k:&quot;</span>, linewidth=<span class="hljs-number">2</span>)<br>plt.plot(np.sqrt(val_errors), <span class="hljs-string">&quot;b-&quot;</span>, linewidth=<span class="hljs-number">3</span>, label=<span class="hljs-string">&quot;Validation set&quot;</span>)<br>plt.plot(np.sqrt(train_errors), <span class="hljs-string">&quot;r--&quot;</span>, linewidth=<span class="hljs-number">2</span>, label=<span class="hljs-string">&quot;Training set&quot;</span>)<br>plt.legend(loc=<span class="hljs-string">&quot;upper right&quot;</span>, fontsize=<span class="hljs-number">14</span>)<br>plt.xlabel(<span class="hljs-string">&quot;Epoch&quot;</span>, fontsize=<span class="hljs-number">14</span>)<br>plt.ylabel(<span class="hljs-string">&quot;RMSE&quot;</span>, fontsize=<span class="hljs-number">14</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>

<p><img src="%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%5Coutput_45_1.png" srcset="/img/loading.gif" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.base <span class="hljs-keyword">import</span> clone<br>sgd_reg = SGDRegressor(max_iter=<span class="hljs-number">1</span>, warm_start=<span class="hljs-literal">True</span>, penalty=<span class="hljs-literal">None</span>,<br>                       learning_rate=<span class="hljs-string">&quot;constant&quot;</span>, eta0=<span class="hljs-number">0.0005</span>, random_state=<span class="hljs-number">42</span>)<br><br>minimum_val_error = <span class="hljs-built_in">float</span>(<span class="hljs-string">&quot;inf&quot;</span>)<br>best_epoch = <span class="hljs-literal">None</span><br>best_model = <span class="hljs-literal">None</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>):<br>    sgd_reg.fit(X_train_poly_scaled, y_train)  <span class="hljs-comment"># continues where it left off</span><br>    y_val_predict = sgd_reg.predict(X_val_poly_scaled)<br>    val_error = mean_squared_error(y_val, y_val_predict)<br>    <span class="hljs-keyword">if</span> val_error &lt; minimum_val_error:<br>        minimum_val_error = val_error<br>        best_epoch = epoch<br>        best_model = clone(sgd_reg)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">best_epoch, best_model<br></code></pre></td></tr></table></figure>



<pre><code>(239,
 SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,
        eta0=0.0005, fit_intercept=True, l1_ratio=0.15,
        learning_rate=&#39;constant&#39;, loss=&#39;squared_loss&#39;, max_iter=1,
        n_iter=None, n_iter_no_change=5, penalty=None, power_t=0.25,
        random_state=42, shuffle=True, tol=None, validation_fraction=0.1,
        verbose=0, warm_start=True))</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">%matplotlib inline<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python">t1a, t1b, t2a, t2b = -<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, -<span class="hljs-number">1.5</span>, <span class="hljs-number">1.5</span><br><br><span class="hljs-comment"># ignoring bias term</span><br>t1s = np.linspace(t1a, t1b, <span class="hljs-number">500</span>)<br>t2s = np.linspace(t2a, t2b, <span class="hljs-number">500</span>)<br>t1, t2 = np.meshgrid(t1s, t2s)<br>T = np.c_[t1.ravel(), t2.ravel()]<br>Xr = np.array([[-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>], [-<span class="hljs-number">0.3</span>, -<span class="hljs-number">1</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">0.1</span>]])<br>yr = <span class="hljs-number">2</span> * Xr[:, :<span class="hljs-number">1</span>] + <span class="hljs-number">0.5</span> * Xr[:, <span class="hljs-number">1</span>:]<br><br>J = (<span class="hljs-number">1</span>/<span class="hljs-built_in">len</span>(Xr) * np.<span class="hljs-built_in">sum</span>((T.dot(Xr.T) - yr.T)**<span class="hljs-number">2</span>, axis=<span class="hljs-number">1</span>)).reshape(t1.shape)<br><br>N1 = np.linalg.norm(T, <span class="hljs-built_in">ord</span>=<span class="hljs-number">1</span>, axis=<span class="hljs-number">1</span>).reshape(t1.shape)<br>N2 = np.linalg.norm(T, <span class="hljs-built_in">ord</span>=<span class="hljs-number">2</span>, axis=<span class="hljs-number">1</span>).reshape(t1.shape)<br><br>t_min_idx = np.unravel_index(np.argmin(J), J.shape)<br>t1_min, t2_min = t1[t_min_idx], t2[t_min_idx]<br><br>t_init = np.array([[<span class="hljs-number">0.25</span>], [-<span class="hljs-number">1</span>]])<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">bgd_path</span>(<span class="hljs-params">theta, X, y, l1, l2, core = <span class="hljs-number">1</span>, eta = <span class="hljs-number">0.1</span>, n_iterations = <span class="hljs-number">50</span></span>):</span><br>    path = [theta]<br>    <span class="hljs-keyword">for</span> iteration <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_iterations):<br>        gradients = core * <span class="hljs-number">2</span>/<span class="hljs-built_in">len</span>(X) * X.T.dot(X.dot(theta) - y) + l1 * np.sign(theta) + <span class="hljs-number">2</span> * l2 * theta<br><br>        theta = theta - eta * gradients<br>        path.append(theta)<br>    <span class="hljs-keyword">return</span> np.array(path)<br><br>plt.figure(figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">8</span>))<br><span class="hljs-keyword">for</span> i, N, l1, l2, title <span class="hljs-keyword">in</span> ((<span class="hljs-number">0</span>, N1, <span class="hljs-number">0.5</span>, <span class="hljs-number">0</span>, <span class="hljs-string">&quot;Lasso&quot;</span>), (<span class="hljs-number">1</span>, N2, <span class="hljs-number">0</span>,  <span class="hljs-number">0.1</span>, <span class="hljs-string">&quot;Ridge&quot;</span>)):<br>    JR = J + l1 * N1 + l2 * N2**<span class="hljs-number">2</span><br>    <br>    tr_min_idx = np.unravel_index(np.argmin(JR), JR.shape)<br>    t1r_min, t2r_min = t1[tr_min_idx], t2[tr_min_idx]<br><br>    levelsJ=(np.exp(np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">20</span>)) - <span class="hljs-number">1</span>) * (np.<span class="hljs-built_in">max</span>(J) - np.<span class="hljs-built_in">min</span>(J)) + np.<span class="hljs-built_in">min</span>(J)<br>    levelsJR=(np.exp(np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">20</span>)) - <span class="hljs-number">1</span>) * (np.<span class="hljs-built_in">max</span>(JR) - np.<span class="hljs-built_in">min</span>(JR)) + np.<span class="hljs-built_in">min</span>(JR)<br>    levelsN=np.linspace(<span class="hljs-number">0</span>, np.<span class="hljs-built_in">max</span>(N), <span class="hljs-number">10</span>)<br>    <br>    path_J = bgd_path(t_init, Xr, yr, l1=<span class="hljs-number">0</span>, l2=<span class="hljs-number">0</span>)<br>    path_JR = bgd_path(t_init, Xr, yr, l1, l2)<br>    path_N = bgd_path(t_init, Xr, yr, np.sign(l1)/<span class="hljs-number">3</span>, np.sign(l2), core=<span class="hljs-number">0</span>)<br><br>    plt.subplot(<span class="hljs-number">221</span> + i * <span class="hljs-number">2</span>)<br>    plt.grid(<span class="hljs-literal">True</span>)<br>    plt.axhline(y=<span class="hljs-number">0</span>, color=<span class="hljs-string">&#x27;k&#x27;</span>)<br>    plt.axvline(x=<span class="hljs-number">0</span>, color=<span class="hljs-string">&#x27;k&#x27;</span>)<br>    plt.contourf(t1, t2, J, levels=levelsJ, alpha=<span class="hljs-number">0.9</span>)<br>    plt.contour(t1, t2, N, levels=levelsN)<br>    plt.plot(path_J[:, <span class="hljs-number">0</span>], path_J[:, <span class="hljs-number">1</span>], <span class="hljs-string">&quot;w-o&quot;</span>)<br>    plt.plot(path_N[:, <span class="hljs-number">0</span>], path_N[:, <span class="hljs-number">1</span>], <span class="hljs-string">&quot;y-^&quot;</span>)<br>    plt.plot(t1_min, t2_min, <span class="hljs-string">&quot;rs&quot;</span>)<br>    plt.title(<span class="hljs-string">r&quot;$\ell_&#123;&#125;$ penalty&quot;</span>.<span class="hljs-built_in">format</span>(i + <span class="hljs-number">1</span>), fontsize=<span class="hljs-number">16</span>)<br>    plt.axis([t1a, t1b, t2a, t2b])<br>    <span class="hljs-keyword">if</span> i == <span class="hljs-number">1</span>:<br>        plt.xlabel(<span class="hljs-string">r&quot;$\theta_1$&quot;</span>, fontsize=<span class="hljs-number">20</span>)<br>    plt.ylabel(<span class="hljs-string">r&quot;$\theta_2$&quot;</span>, fontsize=<span class="hljs-number">20</span>, rotation=<span class="hljs-number">0</span>)<br><br>    plt.subplot(<span class="hljs-number">222</span> + i * <span class="hljs-number">2</span>)<br>    plt.grid(<span class="hljs-literal">True</span>)<br>    plt.axhline(y=<span class="hljs-number">0</span>, color=<span class="hljs-string">&#x27;k&#x27;</span>)<br>    plt.axvline(x=<span class="hljs-number">0</span>, color=<span class="hljs-string">&#x27;k&#x27;</span>)<br>    plt.contourf(t1, t2, JR, levels=levelsJR, alpha=<span class="hljs-number">0.9</span>)<br>    plt.plot(path_JR[:, <span class="hljs-number">0</span>], path_JR[:, <span class="hljs-number">1</span>], <span class="hljs-string">&quot;w-o&quot;</span>)<br>    plt.plot(t1r_min, t2r_min, <span class="hljs-string">&quot;rs&quot;</span>)<br>    plt.title(title, fontsize=<span class="hljs-number">16</span>)<br>    plt.axis([t1a, t1b, t2a, t2b])<br>    <span class="hljs-keyword">if</span> i == <span class="hljs-number">1</span>:<br>        plt.xlabel(<span class="hljs-string">r&quot;$\theta_1$&quot;</span>, fontsize=<span class="hljs-number">20</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>

<p><img src="%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%5Coutput_50_0.png" srcset="/img/loading.gif" alt="png"></p>
<h2 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">t = np.linspace(-<span class="hljs-number">10</span>, <span class="hljs-number">10</span>, <span class="hljs-number">100</span>)<br>sig = <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(-t))<br>plt.figure(figsize=(<span class="hljs-number">9</span>, <span class="hljs-number">3</span>))<br>plt.plot([-<span class="hljs-number">10</span>, <span class="hljs-number">10</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>], <span class="hljs-string">&quot;k-&quot;</span>)<br>plt.plot([-<span class="hljs-number">10</span>, <span class="hljs-number">10</span>], [<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>], <span class="hljs-string">&quot;k:&quot;</span>)<br>plt.plot([-<span class="hljs-number">10</span>, <span class="hljs-number">10</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>], <span class="hljs-string">&quot;k:&quot;</span>)<br>plt.plot([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [-<span class="hljs-number">1.1</span>, <span class="hljs-number">1.1</span>], <span class="hljs-string">&quot;k-&quot;</span>)<br>plt.plot(t, sig, <span class="hljs-string">&quot;b-&quot;</span>, linewidth=<span class="hljs-number">2</span>, label=<span class="hljs-string">r&quot;$\sigma(t) = \frac&#123;1&#125;&#123;1 + e^&#123;-t&#125;&#125;$&quot;</span>)<br>plt.xlabel(<span class="hljs-string">&quot;t&quot;</span>)<br>plt.legend(loc=<span class="hljs-string">&quot;upper left&quot;</span>, fontsize=<span class="hljs-number">20</span>)<br>plt.axis([-<span class="hljs-number">10</span>, <span class="hljs-number">10</span>, -<span class="hljs-number">0.1</span>, <span class="hljs-number">1.1</span>])<br>plt.show()<br></code></pre></td></tr></table></figure>

<p><img src="%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%5Coutput_52_0.png" srcset="/img/loading.gif" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets<br>iris = datasets.load_iris()<br><span class="hljs-built_in">list</span>(iris.keys())<br></code></pre></td></tr></table></figure>



<pre><code>[&#39;data&#39;, &#39;target&#39;, &#39;target_names&#39;, &#39;DESCR&#39;, &#39;feature_names&#39;, &#39;filename&#39;]</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">print(iris.DESCR)<br></code></pre></td></tr></table></figure>
<pre><code>.. _iris_dataset:

Iris plants dataset
--------------------

**Data Set Characteristics:**

    :Number of Instances: 150 (50 in each of three classes)
    :Number of Attributes: 4 numeric, predictive attributes and the class
    :Attribute Information:
        - sepal length in cm
        - sepal width in cm
        - petal length in cm
        - petal width in cm
        - class:
                - Iris-Setosa
                - Iris-Versicolour
                - Iris-Virginica

    :Summary Statistics:

    ============== ==== ==== ======= ===== ====================
                    Min  Max   Mean    SD   Class Correlation
    ============== ==== ==== ======= ===== ====================
    sepal length:   4.3  7.9   5.84   0.83    0.7826
    sepal width:    2.0  4.4   3.05   0.43   -0.4194
    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)
    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)
    ============== ==== ==== ======= ===== ====================

    :Missing Attribute Values: None
    :Class Distribution: 33.3% for each of 3 classes.
    :Creator: R.A. Fisher
    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)
    :Date: July, 1988

The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken
from Fisher&#39;s paper. Note that it&#39;s the same as in R, but not as in the UCI
Machine Learning Repository, which has two wrong data points.

This is perhaps the best known database to be found in the
pattern recognition literature.  Fisher&#39;s paper is a classic in the field and
is referenced frequently to this day.  (See Duda &amp; Hart, for example.)  The
data set contains 3 classes of 50 instances each, where each class refers to a
type of iris plant.  One class is linearly separable from the other 2; the
latter are NOT linearly separable from each other.

.. topic:: References

   - Fisher, R.A. &quot;The use of multiple measurements in taxonomic problems&quot;
     Annual Eugenics, 7, Part II, 179-188 (1936); also in &quot;Contributions to
     Mathematical Statistics&quot; (John Wiley, NY, 1950).
   - Duda, R.O., &amp; Hart, P.E. (1973) Pattern Classification and Scene Analysis.
     (Q327.D83) John Wiley &amp; Sons.  ISBN 0-471-22361-1.  See page 218.
   - Dasarathy, B.V. (1980) &quot;Nosing Around the Neighborhood: A New System
     Structure and Classification Rule for Recognition in Partially Exposed
     Environments&quot;.  IEEE Transactions on Pattern Analysis and Machine
     Intelligence, Vol. PAMI-2, No. 1, 67-71.
   - Gates, G.W. (1972) &quot;The Reduced Nearest Neighbor Rule&quot;.  IEEE Transactions
     on Information Theory, May 1972, 431-433.
   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al&quot;s AUTOCLASS II
     conceptual clustering system finds 3 classes in the data.
   - Many, many more ...</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">X = iris[<span class="hljs-string">&quot;data&quot;</span>][:, <span class="hljs-number">3</span>:]  <span class="hljs-comment"># petal width</span><br>y = (iris[<span class="hljs-string">&quot;target&quot;</span>] == <span class="hljs-number">2</span>).astype(np.<span class="hljs-built_in">int</span>)  <span class="hljs-comment"># 1 if Iris-Virginica, else 0</span><br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br>log_reg = LogisticRegression(random_state=<span class="hljs-number">42</span>)<br>log_reg.fit(X, y)<br></code></pre></td></tr></table></figure>
<pre><code>D:\Anaconda\Lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)





LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class=&#39;warn&#39;,
          n_jobs=None, penalty=&#39;l2&#39;, random_state=42, solver=&#39;warn&#39;,
          tol=0.0001, verbose=0, warm_start=False)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">X_new = np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1000</span>).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>y_proba = log_reg.predict_proba(X_new)<br><br>plt.plot(X_new, y_proba[:, <span class="hljs-number">1</span>], <span class="hljs-string">&quot;g-&quot;</span>, linewidth=<span class="hljs-number">2</span>, label=<span class="hljs-string">&quot;Iris-Virginica&quot;</span>)<br>plt.plot(X_new, y_proba[:, <span class="hljs-number">0</span>], <span class="hljs-string">&quot;b--&quot;</span>, linewidth=<span class="hljs-number">2</span>, label=<span class="hljs-string">&quot;Not Iris-Virginica&quot;</span>)<br></code></pre></td></tr></table></figure>



<pre><code>[&lt;matplotlib.lines.Line2D at 0x24cd5d7d8d0&gt;]</code></pre>
<p><img src="%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%5Coutput_57_1.png" srcset="/img/loading.gif" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">X_new = np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1000</span>).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>y_proba = log_reg.predict_proba(X_new)<br>decision_boundary = X_new[y_proba[:, <span class="hljs-number">1</span>] &gt;= <span class="hljs-number">0.5</span>][<span class="hljs-number">0</span>]<br><br>plt.figure(figsize=(<span class="hljs-number">8</span>, <span class="hljs-number">3</span>))<br>plt.plot(X[y==<span class="hljs-number">0</span>], y[y==<span class="hljs-number">0</span>], <span class="hljs-string">&quot;bs&quot;</span>)<br>plt.plot(X[y==<span class="hljs-number">1</span>], y[y==<span class="hljs-number">1</span>], <span class="hljs-string">&quot;g^&quot;</span>)<br>plt.plot([decision_boundary, decision_boundary], [-<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], <span class="hljs-string">&quot;k:&quot;</span>, linewidth=<span class="hljs-number">2</span>)<br>plt.plot(X_new, y_proba[:, <span class="hljs-number">1</span>], <span class="hljs-string">&quot;g-&quot;</span>, linewidth=<span class="hljs-number">2</span>, label=<span class="hljs-string">&quot;Iris-Virginica&quot;</span>)<br>plt.plot(X_new, y_proba[:, <span class="hljs-number">0</span>], <span class="hljs-string">&quot;b--&quot;</span>, linewidth=<span class="hljs-number">2</span>, label=<span class="hljs-string">&quot;Not Iris-Virginica&quot;</span>)<br>plt.text(decision_boundary+<span class="hljs-number">0.02</span>, <span class="hljs-number">0.15</span>, <span class="hljs-string">&quot;Decision  boundary&quot;</span>, fontsize=<span class="hljs-number">14</span>, color=<span class="hljs-string">&quot;k&quot;</span>, ha=<span class="hljs-string">&quot;center&quot;</span>)<br>plt.arrow(decision_boundary, <span class="hljs-number">0.08</span>, -<span class="hljs-number">0.3</span>, <span class="hljs-number">0</span>, head_width=<span class="hljs-number">0.05</span>, head_length=<span class="hljs-number">0.1</span>, fc=<span class="hljs-string">&#x27;b&#x27;</span>, ec=<span class="hljs-string">&#x27;b&#x27;</span>)<br>plt.arrow(decision_boundary, <span class="hljs-number">0.92</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0</span>, head_width=<span class="hljs-number">0.05</span>, head_length=<span class="hljs-number">0.1</span>, fc=<span class="hljs-string">&#x27;g&#x27;</span>, ec=<span class="hljs-string">&#x27;g&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&quot;Petal width (cm)&quot;</span>, fontsize=<span class="hljs-number">14</span>)<br>plt.ylabel(<span class="hljs-string">&quot;Probability&quot;</span>, fontsize=<span class="hljs-number">14</span>)<br>plt.legend(loc=<span class="hljs-string">&quot;center left&quot;</span>, fontsize=<span class="hljs-number">14</span>)<br>plt.axis([<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, -<span class="hljs-number">0.02</span>, <span class="hljs-number">1.02</span>])<br>plt.show()<br></code></pre></td></tr></table></figure>

<p><img src="%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%5Coutput_58_0.png" srcset="/img/loading.gif" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">decision_boundary<br></code></pre></td></tr></table></figure>



<pre><code>array([ 1.61561562])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">log_reg.predict([[<span class="hljs-number">1.7</span>], [<span class="hljs-number">1.5</span>]])<br></code></pre></td></tr></table></figure>



<pre><code>array([1, 0])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><br>X = iris[<span class="hljs-string">&quot;data&quot;</span>][:, (<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)]  <span class="hljs-comment"># petal length, petal width</span><br>y = (iris[<span class="hljs-string">&quot;target&quot;</span>] == <span class="hljs-number">2</span>).astype(np.<span class="hljs-built_in">int</span>)<br><br>log_reg = LogisticRegression(C=<span class="hljs-number">10</span>**<span class="hljs-number">10</span>, random_state=<span class="hljs-number">42</span>)<br>log_reg.fit(X, y)<br><br>x0, x1 = np.meshgrid(<br>        np.linspace(<span class="hljs-number">2.9</span>, <span class="hljs-number">7</span>, <span class="hljs-number">500</span>).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>),<br>        np.linspace(<span class="hljs-number">0.8</span>, <span class="hljs-number">2.7</span>, <span class="hljs-number">200</span>).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>),<br>    )<br>X_new = np.c_[x0.ravel(), x1.ravel()]<br><br>y_proba = log_reg.predict_proba(X_new)<br><br>plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">4</span>))<br>plt.plot(X[y==<span class="hljs-number">0</span>, <span class="hljs-number">0</span>], X[y==<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], <span class="hljs-string">&quot;bs&quot;</span>)<br>plt.plot(X[y==<span class="hljs-number">1</span>, <span class="hljs-number">0</span>], X[y==<span class="hljs-number">1</span>, <span class="hljs-number">1</span>], <span class="hljs-string">&quot;g^&quot;</span>)<br><br>zz = y_proba[:, <span class="hljs-number">1</span>].reshape(x0.shape)<br>contour = plt.contour(x0, x1, zz, cmap=plt.cm.brg)<br><br><br>left_right = np.array([<span class="hljs-number">2.9</span>, <span class="hljs-number">7</span>])<br>boundary = -(log_reg.coef_[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] * left_right + log_reg.intercept_[<span class="hljs-number">0</span>]) / log_reg.coef_[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]<br><br>plt.clabel(contour, inline=<span class="hljs-number">1</span>, fontsize=<span class="hljs-number">12</span>)<br>plt.plot(left_right, boundary, <span class="hljs-string">&quot;k--&quot;</span>, linewidth=<span class="hljs-number">3</span>)<br>plt.text(<span class="hljs-number">3.5</span>, <span class="hljs-number">1.5</span>, <span class="hljs-string">&quot;Not Iris-Virginica&quot;</span>, fontsize=<span class="hljs-number">14</span>, color=<span class="hljs-string">&quot;b&quot;</span>, ha=<span class="hljs-string">&quot;center&quot;</span>)<br>plt.text(<span class="hljs-number">6.5</span>, <span class="hljs-number">2.3</span>, <span class="hljs-string">&quot;Iris-Virginica&quot;</span>, fontsize=<span class="hljs-number">14</span>, color=<span class="hljs-string">&quot;g&quot;</span>, ha=<span class="hljs-string">&quot;center&quot;</span>)<br>plt.xlabel(<span class="hljs-string">&quot;Petal length&quot;</span>, fontsize=<span class="hljs-number">14</span>)<br>plt.ylabel(<span class="hljs-string">&quot;Petal width&quot;</span>, fontsize=<span class="hljs-number">14</span>)<br>plt.axis([<span class="hljs-number">2.9</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0.8</span>, <span class="hljs-number">2.7</span>])<br>plt.show()<br></code></pre></td></tr></table></figure>
<pre><code>D:\Anaconda\Lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)</code></pre>
<p><img src="%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%5Coutput_61_1.png" srcset="/img/loading.gif" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">X = iris[<span class="hljs-string">&quot;data&quot;</span>][:, (<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)]  <span class="hljs-comment"># petal length, petal width</span><br>y = iris[<span class="hljs-string">&quot;target&quot;</span>]<br><br>softmax_reg = LogisticRegression(multi_class=<span class="hljs-string">&quot;multinomial&quot;</span>,solver=<span class="hljs-string">&quot;lbfgs&quot;</span>, C=<span class="hljs-number">10</span>, random_state=<span class="hljs-number">42</span>)<br>softmax_reg.fit(X, y)<br></code></pre></td></tr></table></figure>



<pre><code>LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class=&#39;multinomial&#39;,
          n_jobs=None, penalty=&#39;l2&#39;, random_state=42, solver=&#39;lbfgs&#39;,
          tol=0.0001, verbose=0, warm_start=False)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python">x0, x1 = np.meshgrid(<br>        np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">8</span>, <span class="hljs-number">500</span>).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>),<br>        np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">3.5</span>, <span class="hljs-number">200</span>).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>),<br>    )<br>X_new = np.c_[x0.ravel(), x1.ravel()]<br><br><br>y_proba = softmax_reg.predict_proba(X_new)<br>y_predict = softmax_reg.predict(X_new)<br><br>zz1 = y_proba[:, <span class="hljs-number">1</span>].reshape(x0.shape)<br>zz = y_predict.reshape(x0.shape)<br><br>plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">4</span>))<br>plt.plot(X[y==<span class="hljs-number">2</span>, <span class="hljs-number">0</span>], X[y==<span class="hljs-number">2</span>, <span class="hljs-number">1</span>], <span class="hljs-string">&quot;g^&quot;</span>, label=<span class="hljs-string">&quot;Iris-Virginica&quot;</span>)<br>plt.plot(X[y==<span class="hljs-number">1</span>, <span class="hljs-number">0</span>], X[y==<span class="hljs-number">1</span>, <span class="hljs-number">1</span>], <span class="hljs-string">&quot;bs&quot;</span>, label=<span class="hljs-string">&quot;Iris-Versicolor&quot;</span>)<br>plt.plot(X[y==<span class="hljs-number">0</span>, <span class="hljs-number">0</span>], X[y==<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], <span class="hljs-string">&quot;yo&quot;</span>, label=<span class="hljs-string">&quot;Iris-Setosa&quot;</span>)<br><br><span class="hljs-keyword">from</span> matplotlib.colors <span class="hljs-keyword">import</span> ListedColormap<br>custom_cmap = ListedColormap([<span class="hljs-string">&#x27;#fafab0&#x27;</span>,<span class="hljs-string">&#x27;#9898ff&#x27;</span>,<span class="hljs-string">&#x27;#a0faa0&#x27;</span>])<br><br>plt.contourf(x0, x1, zz, cmap=custom_cmap)<br>contour = plt.contour(x0, x1, zz1, cmap=plt.cm.brg)<br>plt.clabel(contour, inline=<span class="hljs-number">1</span>, fontsize=<span class="hljs-number">12</span>)<br>plt.xlabel(<span class="hljs-string">&quot;Petal length&quot;</span>, fontsize=<span class="hljs-number">14</span>)<br>plt.ylabel(<span class="hljs-string">&quot;Petal width&quot;</span>, fontsize=<span class="hljs-number">14</span>)<br>plt.legend(loc=<span class="hljs-string">&quot;center left&quot;</span>, fontsize=<span class="hljs-number">14</span>)<br>plt.axis([<span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3.5</span>])<br>plt.show()<br></code></pre></td></tr></table></figure>

<p><img src="%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%5Coutput_63_0.png" srcset="/img/loading.gif" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">softmax_reg.predict([[<span class="hljs-number">5</span>, <span class="hljs-number">2</span>]])<br></code></pre></td></tr></table></figure>



<pre><code>array([2])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">softmax_reg.predict_proba([[<span class="hljs-number">5</span>, <span class="hljs-number">2</span>]])<br></code></pre></td></tr></table></figure>



<pre><code>array([[  6.38014896e-07,   5.74929995e-02,   9.42506362e-01]])</code></pre>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/">机器学习入门</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2019/04/09/%E4%BA%8C%E5%88%86%E7%B1%BB%E5%99%A8%E5%8F%8A%E5%85%B6%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">二分类及其性能指标</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2019/04/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B/">
                        <span class="hidden-mobile">机器学习基本流程</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>

<!-- SCRIPTS -->

  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.0/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.0/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js" ></script>






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    (function () {
      var path = "/local-search.xml";
      var inputArea = document.querySelector("#local-search-input");
      inputArea.onclick = function () {
        searchFunc(path, 'local-search-input', 'local-search-result');
        this.onclick = null
      }
    })()
  </script>















<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>



</body>
</html>
