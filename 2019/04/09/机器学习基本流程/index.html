

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  <title>机器学习基本流程 - Hexo</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.4.0/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.7","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":2},"lazyload":{"enable":true,"onlypost":false},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}}};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.3.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>windilycloud</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="机器学习基本流程">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2019-04-09 00:00" pubdate>
        2019年4月9日 凌晨
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      4.5k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      72
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">机器学习基本流程</h1>
            
            <div class="markdown-body">
              <p>以泰坦尼克号乘客存活率为例</p>
<p>大纲：</p>
<ol>
<li>宏观上定义问题，明确目标，选择性能指标，检查假设的合理性。</li>
<li>建立工作空间，加载数据集，浏览数据结构和含义，划分测试集。</li>
<li>探索性数据可视化，发现数据之间的关系，实验数据组合。</li>
<li>数据清洗，处理非数字类型数据，建立处理管道，为后续算法做准备。</li>
<li>选择和训练模型，计算性能指标，进行交叉验证，保存模型。</li>
<li>优化模型，网格搜索，随即搜索，集成方法等，并分析出最好的模型或模型组合，计算出性能指标。</li>
<li>加载，监控，维持系统的稳定性。</li>
</ol>
<h1 id="定义问题"><a href="#定义问题" class="headerlink" title="定义问题"></a>定义问题</h1><p>问题描述： RMS泰坦尼克号的沉没是历史上最臭名昭着的沉船之一。 1912年4月15日，在她的处女航中，泰坦尼克号在与冰山相撞后沉没，在2224名船员造成1502人死亡。 这场耸人听闻的悲剧震惊了国际社会，并为船舶制定了更好的安全规定。船舶残骸造成这种生命损失的原因之一是乘客和船员没有足够的救生艇。 虽然有一些运气因素涉及到沉没，但有些人比其他人更容易生存，比如妇女，儿童和上流社会。在这次挑战中，我们要求您完成对哪些人可能存活的分析。 特别是，我们要求您运用机器学习工具来预测哪些乘客在悲剧中幸存下来。 </p>
<ul>
<li>目标： 通过数据预测一个人是否会在此次灾难中存活。 </li>
<li>性能指标： 这是一个二分类问题，将一个人分为是生，还是死。性能指标可以用精度，召回率来表征。</li>
</ul>
<h1 id="速览数据结构"><a href="#速览数据结构" class="headerlink" title="速览数据结构"></a>速览数据结构</h1><ul>
<li>工作空间：新建一个文件夹，创建代码文件夹，数据集文件夹，图表文件夹</li>
<li>加载数据集：可以线上加载，也可以线下，这里已直接下载到本地数据集文件夹中</li>
<li>代码空间： 加载相应的库，设置路径，图表大小等相应的格式</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> matplotlib<br>%matplotlib inline<br>plt.rcParams[<span class="hljs-string">&#x27;axes.labelsize&#x27;</span>] = <span class="hljs-number">14</span><br>plt.rcParams[<span class="hljs-string">&#x27;xtick.labelsize&#x27;</span>] = <span class="hljs-number">12</span><br>plt.rcParams[<span class="hljs-string">&#x27;ytick.labelsize&#x27;</span>] = <span class="hljs-number">12</span><br></code></pre></td></tr></table></figure>
<h2 id="粗略信息"><a href="#粗略信息" class="headerlink" title="粗略信息"></a>粗略信息</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#加载数据集，已放在工作目录下</span><br>dataset = pd.read_csv(<span class="hljs-string">&quot;titanic.csv&quot;</span>)<br><span class="hljs-comment">#常用的几个查看数据集的方式</span><br>dataset.head(<span class="hljs-number">20</span>)<br><span class="hljs-comment">#pclass-客舱等级</span><br><span class="hljs-comment">#slibsp-兄弟姐妹数/配偶数</span><br><span class="hljs-comment">#parch-父母数/子女数</span><br><span class="hljs-comment">#ticket-船票编号</span><br><span class="hljs-comment">#fare-船票价格</span><br><span class="hljs-comment">#cabin-客舱号</span><br><span class="hljs-comment">#embarket-登船港口</span><br></code></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">dataset.info()<br><span class="hljs-comment">#由此易得，年龄，船票价格，客舱号，登船港口有缺失值，其中年龄和客舱号缺失严重。</span><br></code></pre></td></tr></table></figure>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 1309 entries, 0 to 1308
Data columns (total 11 columns):
pclass      1309 non-null int64
name        1309 non-null object
sex         1309 non-null object
age         1046 non-null float64
sibsp       1309 non-null int64
parch       1309 non-null int64
ticket      1309 non-null object
fare        1308 non-null float64
cabin       295 non-null object
embarked    1307 non-null object
survived    1309 non-null int64
dtypes: float64(2), int64(4), object(5)
memory usage: 112.6+ KB</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">dataset.describe()<br><span class="hljs-comment">#看出年龄有问题，最小0.1667,怎么还精确到小数点后几位的？费用也需要注意一下，免费上船？</span><br></code></pre></td></tr></table></figure>



<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pclass</th>
      <th>age</th>
      <th>sibsp</th>
      <th>parch</th>
      <th>fare</th>
      <th>survived</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1309.000000</td>
      <td>1046.000000</td>
      <td>1309.000000</td>
      <td>1309.000000</td>
      <td>1308.000000</td>
      <td>1309.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2.294882</td>
      <td>29.881135</td>
      <td>0.498854</td>
      <td>0.385027</td>
      <td>33.295479</td>
      <td>0.381971</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.837836</td>
      <td>14.413500</td>
      <td>1.041658</td>
      <td>0.865560</td>
      <td>51.758668</td>
      <td>0.486055</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>0.166700</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>2.000000</td>
      <td>21.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>7.895800</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>3.000000</td>
      <td>28.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>14.454200</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>3.000000</td>
      <td>39.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>31.275000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>3.000000</td>
      <td>80.000000</td>
      <td>8.000000</td>
      <td>9.000000</td>
      <td>512.329200</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>

</div>






<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">dataset.hist(bins = <span class="hljs-number">50</span>, figsize = (<span class="hljs-number">20</span>,<span class="hljs-number">15</span>))<br>plt.show()<br></code></pre></td></tr></table></figure>

<p><img src="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B%5Coutput_8_0.png" srcset="/img/loading.gif" alt="png"></p>
<h2 id="创建测试集"><a href="#创建测试集" class="headerlink" title="创建测试集"></a>创建测试集</h2><p>切记在看更多详细信息之前，应划分测试集，并把它放到一边<br>划分数据集有两个方法，一个手动（用numpy自己分割），一个自动（sklearn写好的api）<br>手动方法适应个性化操作。</p>
<ul>
<li>数据集过小，单纯的随机创建会产生样本倾斜，采取分层抽样的方式平衡关键属性（看书）</li>
</ul>
<p>手动划分</p>
<figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-meta"># For illustration only. Sklearn has train_test_split()</span><br><span class="hljs-title">def</span> split_train_test(<span class="hljs-class"><span class="hljs-keyword">data</span>, test_ratio):</span><br>    shuffled_indices = np.random.permutation(len(<span class="hljs-class"><span class="hljs-keyword">data</span>))</span><br>    test_set_size = int(len(<span class="hljs-class"><span class="hljs-keyword">data</span>) * test_ratio)</span><br>    test_indices = shuffled_indices[:test_set_size]<br>    train_indices = shuffled_indices[test_set_size:]<br>    return <span class="hljs-class"><span class="hljs-keyword">data</span>.iloc[train_indices], <span class="hljs-keyword">data</span>.iloc[test_indices]</span><br></code></pre></td></tr></table></figure>
<p>需要注意的问题：</p>
<ul>
<li>在每次运行都会生成不同的测试集，解决方法一种是保存下来，另一种是在使用np.random.permutation()时先生成随机种子np.random.seed()</li>
<li>即使确定了随机种子，在数据集更新的时候，依然会出现不同的测试集。解决方法是用对每个 实例的标识符哈希化，看书。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#自动划分</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br>train_set,test_set = train_test_split(dataset, test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">42</span>)<br>print(<span class="hljs-built_in">len</span>(train_set),<span class="hljs-string">&quot;train +&quot;</span>,<span class="hljs-built_in">len</span>(test_set),<span class="hljs-string">&quot;test&quot;</span>)<br></code></pre></td></tr></table></figure>
<pre><code>916 train + 393 test</code></pre>
<h2 id="详细信息"><a href="#详细信息" class="headerlink" title="详细信息"></a>详细信息</h2><ul>
<li>为了避免发生错误影响数据集，使用训练集的副本。</li>
<li>相关性：主要是看数据趋势是否是正相关和负相关，用散点图很容易就看出来了。其中相关系数可以且只能看出是否是线性相关，散列矩阵则比较强大。对于过多的离散点是否需要采用标准化降低模型拟合时间也有重要指导作用。</li>
<li>属性组合：对于多属性反映同一个事物可以考虑合而为一，或者优化属性。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">titanic = train_set.copy()<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 查看数据之间的相关系数</span><br>corr_matrix = titanic.corr()<br>corr_matrix[<span class="hljs-string">&quot;fare&quot;</span>]<br></code></pre></td></tr></table></figure>



<pre><code>pclass     -0.555562
age         0.137666
sibsp       0.158024
parch       0.214890
fare        1.000000
survived    0.261934
Name: fare, dtype: float64</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#数据之间的相关性可视化</span><br><span class="hljs-keyword">from</span> pandas.plotting <span class="hljs-keyword">import</span> scatter_matrix<br><br>attributes = [<span class="hljs-string">&quot;pclass&quot;</span>,<span class="hljs-string">&quot;age&quot;</span>,<span class="hljs-string">&quot;sibsp&quot;</span>,<span class="hljs-string">&quot;parch&quot;</span>,<span class="hljs-string">&quot;fare&quot;</span>,<span class="hljs-string">&quot;survived&quot;</span>]<br>scatter_matrix(titanic[attributes], figsize=(<span class="hljs-number">24</span>, <span class="hljs-number">16</span>))<br>plt.show()<br></code></pre></td></tr></table></figure>

<p><img src="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B%5Coutput_15_0.png" srcset="/img/loading.gif" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#单独拿一个出来看看，为什么感觉青壮年活的多，死的也多，可能是因为基数大吧。</span><br>titanic.plot(kind=<span class="hljs-string">&quot;scatter&quot;</span>, x=<span class="hljs-string">&quot;age&quot;</span>, y=<span class="hljs-string">&quot;survived&quot;</span>,<br>             alpha=<span class="hljs-number">0.1</span>)<br></code></pre></td></tr></table></figure>



<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1d1b182dc88&gt;</code></pre>
<p><img src="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B%5Coutput_16_1.png" srcset="/img/loading.gif" alt="png"></p>
<h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><p>预处理的目的：</p>
<ol>
<li>建立工作流，对于以后更多的数据不必再写代码处理。</li>
<li>逐渐建立自己处理库，复用代码。</li>
<li>易于将数据处理后喂给不同的算法。</li>
</ol>
<p>在这之前我们需要再一次的将数据与对象（结果）分开</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">titanic_data = titanic.drop(<span class="hljs-string">&#x27;survived&#x27;</span>,axis = <span class="hljs-number">1</span>)<br>titanic_label = titanic[<span class="hljs-string">&#x27;survived&#x27;</span>].copy()<br></code></pre></td></tr></table></figure>
<h2 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h2><h3 id="缺失值"><a href="#缺失值" class="headerlink" title="缺失值"></a>缺失值</h3><p>因为大部分机器学习算法对有缺失值的数据特征不能运作，有下列处理方法：</p>
<ul>
<li>直接删除整个属性（缺失值过多）.dropna(subset=[‘attribute’])</li>
<li>删除缺失的部分 .drop(‘attribute’, axis = 1)</li>
<li>填充一些值  ,fillna(value)</li>
</ul>
<p>scikit-learn提供了imputer类进行方便的处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.impute <span class="hljs-keyword">import</span> SimpleImputer <br>imputer = SimpleImputer(strategy = <span class="hljs-string">&#x27;median&#x27;</span>) <br>num_attribs = [<span class="hljs-string">&#x27;pclass&#x27;</span>, <span class="hljs-string">&#x27;age&#x27;</span>, <span class="hljs-string">&#x27;sibsp&#x27;</span>, <span class="hljs-string">&#x27;parch&#x27;</span>, <span class="hljs-string">&#x27;fare&#x27;</span>] <br>titanic_num = titanic_data[num_attribs] <br>imputer.fit(titanic_num)<br></code></pre></td></tr></table></figure>



<pre><code>SimpleImputer(copy=True, fill_value=None, missing_values=nan,
       strategy=&#39;median&#39;, verbose=0)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">print(imputer.statistics_)<br>print(<span class="hljs-string">&#x27;*&#x27;</span>*<span class="hljs-number">30</span>)<br>print(titanic_data.median())<br></code></pre></td></tr></table></figure>
<pre><code>[  3.   28.    0.    0.   14.5]
******************************
pclass     3.0
age       28.0
sibsp      0.0
parch      0.0
fare      14.5
dtype: float64</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">X = imputer.transform(titanic_num) <span class="hljs-comment">#返回结果是numpy，转化为dataframe</span><br>titanic_tr = pd.DataFrame(X,columns=titanic_num.columns)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">titanic_tr<br></code></pre></td></tr></table></figure>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }




    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pclass</th>
      <th>age</th>
      <th>sibsp</th>
      <th>parch</th>
      <th>fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>8.6625</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3.0</td>
      <td>26.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.8958</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2.0</td>
      <td>19.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>26.0000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>69.5500</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.7750</td>
    </tr>
    <tr>
      <th>5</th>
      <td>3.0</td>
      <td>1.0000</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>11.1333</td>
    </tr>
    <tr>
      <th>6</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.2500</td>
    </tr>
    <tr>
      <th>7</th>
      <td>3.0</td>
      <td>30.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>6.9500</td>
    </tr>
    <tr>
      <th>8</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>8.4583</td>
    </tr>
    <tr>
      <th>9</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.7333</td>
    </tr>
    <tr>
      <th>10</th>
      <td>2.0</td>
      <td>52.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>13.0000</td>
    </tr>
    <tr>
      <th>11</th>
      <td>3.0</td>
      <td>20.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>9.5000</td>
    </tr>
    <tr>
      <th>12</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>8.0500</td>
    </tr>
    <tr>
      <th>13</th>
      <td>1.0</td>
      <td>62.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>26.5500</td>
    </tr>
    <tr>
      <th>14</th>
      <td>3.0</td>
      <td>23.5000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.2292</td>
    </tr>
    <tr>
      <th>15</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>8.0500</td>
    </tr>
    <tr>
      <th>16</th>
      <td>3.0</td>
      <td>20.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.2250</td>
    </tr>
    <tr>
      <th>17</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>23.2500</td>
    </tr>
    <tr>
      <th>18</th>
      <td>2.0</td>
      <td>30.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>10.5000</td>
    </tr>
    <tr>
      <th>19</th>
      <td>1.0</td>
      <td>48.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>50.4958</td>
    </tr>
    <tr>
      <th>20</th>
      <td>1.0</td>
      <td>45.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>35.5000</td>
    </tr>
    <tr>
      <th>21</th>
      <td>1.0</td>
      <td>33.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>27.7208</td>
    </tr>
    <tr>
      <th>22</th>
      <td>3.0</td>
      <td>40.5000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>15.1000</td>
    </tr>
    <tr>
      <th>23</th>
      <td>3.0</td>
      <td>27.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.8542</td>
    </tr>
    <tr>
      <th>24</th>
      <td>1.0</td>
      <td>53.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>28.5000</td>
    </tr>
    <tr>
      <th>25</th>
      <td>1.0</td>
      <td>57.0000</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>164.8667</td>
    </tr>
    <tr>
      <th>26</th>
      <td>3.0</td>
      <td>20.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>8.6625</td>
    </tr>
    <tr>
      <th>27</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.5500</td>
    </tr>
    <tr>
      <th>28</th>
      <td>2.0</td>
      <td>24.0000</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>73.5000</td>
    </tr>
    <tr>
      <th>29</th>
      <td>3.0</td>
      <td>2.0000</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>20.2125</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>886</th>
      <td>2.0</td>
      <td>16.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>10.5000</td>
    </tr>
    <tr>
      <th>887</th>
      <td>3.0</td>
      <td>9.0000</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>3.1708</td>
    </tr>
    <tr>
      <th>888</th>
      <td>2.0</td>
      <td>31.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>10.5000</td>
    </tr>
    <tr>
      <th>889</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.7500</td>
    </tr>
    <tr>
      <th>890</th>
      <td>3.0</td>
      <td>0.3333</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>14.4000</td>
    </tr>
    <tr>
      <th>891</th>
      <td>1.0</td>
      <td>61.0000</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>262.3750</td>
    </tr>
    <tr>
      <th>892</th>
      <td>1.0</td>
      <td>47.0000</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>52.5542</td>
    </tr>
    <tr>
      <th>893</th>
      <td>2.0</td>
      <td>42.0000</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>27.0000</td>
    </tr>
    <tr>
      <th>894</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>21.6792</td>
    </tr>
    <tr>
      <th>895</th>
      <td>1.0</td>
      <td>57.0000</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>146.5208</td>
    </tr>
    <tr>
      <th>896</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>25.4667</td>
    </tr>
    <tr>
      <th>897</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.7500</td>
    </tr>
    <tr>
      <th>898</th>
      <td>2.0</td>
      <td>8.0000</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>36.7500</td>
    </tr>
    <tr>
      <th>899</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>56.4958</td>
    </tr>
    <tr>
      <th>900</th>
      <td>2.0</td>
      <td>34.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>13.0000</td>
    </tr>
    <tr>
      <th>901</th>
      <td>3.0</td>
      <td>22.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.2500</td>
    </tr>
    <tr>
      <th>902</th>
      <td>1.0</td>
      <td>22.0000</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>59.4000</td>
    </tr>
    <tr>
      <th>903</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.7500</td>
    </tr>
    <tr>
      <th>904</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>22.3583</td>
    </tr>
    <tr>
      <th>905</th>
      <td>1.0</td>
      <td>27.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>30.5000</td>
    </tr>
    <tr>
      <th>906</th>
      <td>2.0</td>
      <td>57.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>13.0000</td>
    </tr>
    <tr>
      <th>907</th>
      <td>3.0</td>
      <td>25.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.7958</td>
    </tr>
    <tr>
      <th>908</th>
      <td>2.0</td>
      <td>34.0000</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>26.0000</td>
    </tr>
    <tr>
      <th>909</th>
      <td>1.0</td>
      <td>28.0000</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>133.6500</td>
    </tr>
    <tr>
      <th>910</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>15.5000</td>
    </tr>
    <tr>
      <th>911</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.6292</td>
    </tr>
    <tr>
      <th>912</th>
      <td>3.0</td>
      <td>18.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.7750</td>
    </tr>
    <tr>
      <th>913</th>
      <td>3.0</td>
      <td>28.5000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>16.1000</td>
    </tr>
    <tr>
      <th>914</th>
      <td>3.0</td>
      <td>26.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.9250</td>
    </tr>
    <tr>
      <th>915</th>
      <td>3.0</td>
      <td>28.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.8958</td>
    </tr>
  </tbody>
</table>
<p>916 rows × 5 columns</p>
</div>





<h3 id="文本和分类属性"><a href="#文本和分类属性" class="headerlink" title="文本和分类属性"></a>文本和分类属性</h3><ul>
<li>LabelEncoder直接将不同的标签转化为不同的数字，但是这有一个问题，数字与数字之间是有联系的，而标签与标签之间的联系和数字不一样，这样就造成了样本偏斜</li>
<li>OneHot编码能够有效避免上述弊端。因此，一般都采用此方法。文本分类-&gt;标签分类-&gt;onehot分类</li>
<li>文本分类可以直接到Onehot分类，运用LabelBinarizer</li>
<li>这里注意类型，原书中不需要转换成str，这里需要，并且还要转化成array用reshape方法。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> OneHotEncoder<br>cat_attribs = [<span class="hljs-string">&quot;embarked&quot;</span>]<br>titanic_data.embarked.fillna(<span class="hljs-string">&quot;Q&quot;</span>,inplace = <span class="hljs-literal">True</span>)<br>titanic_cat = titanic_data[cat_attribs]<br>encoder = OneHotEncoder()<br>titanic_cat_1hot = encoder.fit_transform(np.array(titanic_cat.astype(<span class="hljs-built_in">str</span>)).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">encoder.categories_<br></code></pre></td></tr></table></figure>



<pre><code>[array([&#39;C&#39;, &#39;Q&#39;, &#39;S&#39;], dtype=object)]</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 原来返回的是稀疏矩阵，对于大规模的数据存储很有好处。可以用toarray改成下列形式</span><br>print(titanic_cat_1hot.toarray())<br></code></pre></td></tr></table></figure>
<pre><code>[[ 0.  0.  1.]
 [ 0.  0.  1.]
 [ 0.  0.  1.]
 ..., 
 [ 0.  0.  1.]
 [ 0.  0.  1.]
 [ 0.  0.  1.]]</code></pre>
<h3 id="自定义变换添加额外属性"><a href="#自定义变换添加额外属性" class="headerlink" title="自定义变换添加额外属性"></a>自定义变换添加额外属性</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.base <span class="hljs-keyword">import</span> BaseEstimator, TransformerMixin<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CombinedAttributesAdder</span>(<span class="hljs-params">BaseEstimator, TransformerMixin</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, add_bedrooms_per_room = <span class="hljs-literal">True</span></span>):</span> <span class="hljs-comment"># no *args or **kargs</span><br>        self.add_bedrooms_per_room = add_bedrooms_per_room<br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fit</span>(<span class="hljs-params">self, X, y=<span class="hljs-literal">None</span></span>):</span><br>        <span class="hljs-keyword">return</span> self  <span class="hljs-comment"># nothing else to do</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">transform</span>(<span class="hljs-params">self, X, y=<span class="hljs-literal">None</span></span>):</span><br>        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]<br>        population_per_household = X[:, population_ix] / X[:, household_ix]<br>        <span class="hljs-keyword">if</span> self.add_bedrooms_per_room:<br>            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]<br>            <span class="hljs-keyword">return</span> np.c_[X, rooms_per_household, population_per_household,<br>                         bedrooms_per_room]<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> np.c_[X, rooms_per_household, population_per_household]<br><br>attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=<span class="hljs-literal">False</span>)<br>housing_extra_attribs = attr_adder.transform(housing.values)<br></code></pre></td></tr></table></figure>
<h3 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.pipeline <span class="hljs-keyword">import</span> Pipeline<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br><br>num_pipeline = Pipeline([<br>        (<span class="hljs-string">&#x27;imputer&#x27;</span>, SimpleImputer(strategy=<span class="hljs-string">&quot;median&quot;</span>)),<br>        <span class="hljs-comment">#(&#x27;attribs_adder&#x27;, CombinedAttributesAdder()),</span><br>        (<span class="hljs-string">&#x27;std_scaler&#x27;</span>, StandardScaler()),<br>    ])<br>titanic_num_tr = num_pipeline.fit_transform(titanic_num)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">titanic_num_tr<br></code></pre></td></tr></table></figure>



<pre><code>array([[ 0.82524778, -0.07091793, -0.49861561, -0.43255344, -0.47409151],
       [ 0.82524778, -0.23259583, -0.49861561, -0.43255344, -0.48861599],
       [-0.36331663, -0.79846845, -0.49861561, -0.43255344, -0.14564735],
       ..., 
       [ 0.82524778, -0.03049846, -0.49861561, -0.43255344, -0.33319441],
       [ 0.82524778, -0.23259583, -0.49861561, -0.43255344, -0.48806282],
       [ 0.82524778, -0.07091793, -0.49861561, -0.43255344, -0.48861599]])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.compose <span class="hljs-keyword">import</span> ColumnTransformer<br><br>full_pipeline = ColumnTransformer([<br>        (<span class="hljs-string">&quot;num&quot;</span>, num_pipeline, num_attribs),<br>        (<span class="hljs-string">&quot;cat&quot;</span>, OneHotEncoder(), cat_attribs),<br>    ])<br>titanic_prepared = full_pipeline.fit_transform(titanic_data)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">titanic_prepared.shape<br></code></pre></td></tr></table></figure>



<pre><code>(916, 8)</code></pre>
<h1 id="选择和训练模型"><a href="#选择和训练模型" class="headerlink" title="选择和训练模型"></a>选择和训练模型</h1><ul>
<li>这里选用的是线性回归模型，仅仅是试一试，可以看出效果是相当不好.显然，一个分类问题用回归模型来训练，显然是错误的</li>
<li>线性回归模型常用均方根来表示误差</li>
<li>随机梯度下降分类器模型看得出有点效果，性能通常用召回率，准确率来表征，这里没有过多展示。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression<br>lin_reg = LinearRegression()<br>lin_reg.fit(titanic_prepared, titanic_label)<br></code></pre></td></tr></table></figure>



<pre><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize=False)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">some_data = test_set.iloc[:<span class="hljs-number">5</span>]<br>some_labels = titanic_label.iloc[:<span class="hljs-number">5</span>]<br>some_data_prepared = full_pipeline.transform(some_data)<br>print(<span class="hljs-string">&quot;Predictions:&quot;</span>, lin_reg.predict(some_data_prepared))<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">print(<span class="hljs-string">&quot;Labels:&quot;</span>, <span class="hljs-built_in">list</span>(some_labels))<br></code></pre></td></tr></table></figure>
<pre><code>Labels: [0, 0, 1, 0, 0]</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error<br><br>titanic_predictions = lin_reg.predict(titanic_prepared)<br>lin_mse = mean_squared_error(titanic_label, titanic_predictions)<br>lin_rmse = np.sqrt(lin_mse)<br>lin_rmse<br></code></pre></td></tr></table></figure>



<pre><code>0.44458368170220458</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_absolute_error<br><br>lin_mae = mean_absolute_error(titanic_label, titanic_predictions)<br>lin_mae<br></code></pre></td></tr></table></figure>



<pre><code>0.39530930007177417</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeRegressor<br><br>tree_reg = DecisionTreeRegressor(random_state=<span class="hljs-number">42</span>)<br>tree_reg.fit(titanic_prepared, titanic_label)<br>housing_predictions = tree_reg.predict(titanic_prepared)<br>tree_mse = mean_squared_error(titanic_label, titanic_predictions)<br>tree_rmse = np.sqrt(tree_mse)<br>tree_rmse<br></code></pre></td></tr></table></figure>



<pre><code>0.44458368170220458</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> SGDClassifier<br><br>sgd_clf = SGDClassifier(max_iter=<span class="hljs-number">5</span>, random_state=<span class="hljs-number">42</span>)<br>sgd_clf.fit(titanic_prepared, titanic_label)<br></code></pre></td></tr></table></figure>



<pre><code>SGDClassifier(alpha=0.0001, average=False, class_weight=None,
       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,
       l1_ratio=0.15, learning_rate=&#39;optimal&#39;, loss=&#39;hinge&#39;, max_iter=5,
       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty=&#39;l2&#39;,
       power_t=0.5, random_state=42, shuffle=True, tol=None,
       validation_fraction=0.1, verbose=0, warm_start=False)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">print(<span class="hljs-string">&quot;Predictions:&quot;</span>, sgd_clf.predict(some_data_prepared))<br></code></pre></td></tr></table></figure>
<pre><code>Predictions: [0 0 0 0 1]</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">print(<span class="hljs-string">&quot;Labels:&quot;</span>, <span class="hljs-built_in">list</span>(some_labels))<br></code></pre></td></tr></table></figure>
<pre><code>Labels: [0, 0, 1, 0, 0]</code></pre>
<h1 id="优化模型"><a href="#优化模型" class="headerlink" title="优化模型"></a>优化模型</h1><ul>
<li>用的最多的就是交叉验证</li>
<li>其次是对模型调参，参数的搜索</li>
<li>最后是对各个模型融合进行预测,得到一个最好的模型就完事了</li>
</ul>
<h2 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> cross_val_score<br><br>scores = cross_val_score(tree_reg, titanic_prepared, titanic_label,<br>                         scoring=<span class="hljs-string">&quot;neg_mean_squared_error&quot;</span>, cv=<span class="hljs-number">5</span>)<br>tree_rmse_scores = np.sqrt(-scores)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">display_scores</span>(<span class="hljs-params">scores</span>):</span><br>    print(<span class="hljs-string">&quot;Scores:&quot;</span>, scores)<br>    print(<span class="hljs-string">&quot;Mean:&quot;</span>, scores.mean())<br>    print(<span class="hljs-string">&quot;Standard deviation:&quot;</span>, scores.std())<br><br>display_scores(tree_rmse_scores)<br></code></pre></td></tr></table></figure>



<pre><code>array([ 0.62210924,  0.59404   ,  0.63470788,  0.58847198,  0.56893364])</code></pre>
<h2 id="参数搜索"><a href="#参数搜索" class="headerlink" title="参数搜索"></a>参数搜索</h2><ul>
<li>给参数自动进行比较，选出最优参数</li>
<li>随机搜索最优参数</li>
</ul>
<h3 id="模型建立"><a href="#模型建立" class="headerlink" title="模型建立"></a>模型建立</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestRegressor<br><br>forest_reg = RandomForestRegressor(random_state=<span class="hljs-number">42</span>)<br>forest_reg.fit(titanic_prepared, titanic_label)<br></code></pre></td></tr></table></figure>
<pre><code>D:\Anaconda\Lib\site-packages\sklearn\ensemble\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
  &quot;10 in version 0.20 to 100 in 0.22.&quot;, FutureWarning)





RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=None,
           max_features=&#39;auto&#39;, max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,
           oob_score=False, random_state=42, verbose=0, warm_start=False)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">titanic_predictions = forest_reg.predict(titanic_prepared)<br>forest_mse = mean_squared_error(titanic_label, titanic_predictions)<br>forest_rmse = np.sqrt(forest_mse)<br>forest_rmse<br></code></pre></td></tr></table></figure>



<pre><code>0.24601252278498684</code></pre>
<h3 id="给定参数搜索"><a href="#给定参数搜索" class="headerlink" title="给定参数搜索"></a>给定参数搜索</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> GridSearchCV<br><br>param_grid = [<br>    <span class="hljs-comment"># try 12 (3×4) combinations of hyperparameters</span><br>    &#123;<span class="hljs-string">&#x27;n_estimators&#x27;</span>: [<span class="hljs-number">3</span>, <span class="hljs-number">10</span>, <span class="hljs-number">30</span>], <span class="hljs-string">&#x27;max_features&#x27;</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">8</span>]&#125;,<br>    <span class="hljs-comment"># then try 6 (2×3) combinations with bootstrap set as False</span><br>    &#123;<span class="hljs-string">&#x27;bootstrap&#x27;</span>: [<span class="hljs-literal">False</span>], <span class="hljs-string">&#x27;n_estimators&#x27;</span>: [<span class="hljs-number">3</span>, <span class="hljs-number">10</span>], <span class="hljs-string">&#x27;max_features&#x27;</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]&#125;,<br>  ]<br><br>forest_reg = RandomForestRegressor(random_state=<span class="hljs-number">42</span>)<br><span class="hljs-comment"># train across 5 folds, that&#x27;s a total of (12+6)*5=90 rounds of training </span><br>grid_search = GridSearchCV(forest_reg, param_grid, cv=<span class="hljs-number">5</span>,<br>                           scoring=<span class="hljs-string">&#x27;neg_mean_squared_error&#x27;</span>, return_train_score=<span class="hljs-literal">True</span>)<br>grid_search.fit(titanic_prepared,titanic_label)<br></code></pre></td></tr></table></figure>



<pre><code>GridSearchCV(cv=5, error_score=&#39;raise-deprecating&#39;,
       estimator=RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=None,
           max_features=&#39;auto&#39;, max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=&#39;warn&#39;, n_jobs=None,
           oob_score=False, random_state=42, verbose=0, warm_start=False),
       fit_params=None, iid=&#39;warn&#39;, n_jobs=None,
       param_grid=[&#123;&#39;n_estimators&#39;: [3, 10, 30], &#39;max_features&#39;: [2, 4, 6, 8]&#125;, &#123;&#39;bootstrap&#39;: [False], &#39;n_estimators&#39;: [3, 10], &#39;max_features&#39;: [2, 3, 4]&#125;],
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=True,
       scoring=&#39;neg_mean_squared_error&#39;, verbose=0)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">grid_search.best_params_<br></code></pre></td></tr></table></figure>



<pre><code>&#123;&#39;max_features&#39;: 8, &#39;n_estimators&#39;: 30&#125;</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">grid_search.best_estimator_<br></code></pre></td></tr></table></figure>



<pre><code>RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=None,
           max_features=8, max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=None, oob_score=False, random_state=42,
           verbose=0, warm_start=False)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">cvres = grid_search.cv_results_<br><span class="hljs-keyword">for</span> mean_score, params <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(cvres[<span class="hljs-string">&quot;mean_test_score&quot;</span>], cvres[<span class="hljs-string">&quot;params&quot;</span>]):<br>    print(np.sqrt(-mean_score), params)<br></code></pre></td></tr></table></figure>
<pre><code>0.497131363834 &#123;&#39;max_features&#39;: 2, &#39;n_estimators&#39;: 3&#125;
0.480945066964 &#123;&#39;max_features&#39;: 2, &#39;n_estimators&#39;: 10&#125;
0.467748997902 &#123;&#39;max_features&#39;: 2, &#39;n_estimators&#39;: 30&#125;
0.502741663175 &#123;&#39;max_features&#39;: 4, &#39;n_estimators&#39;: 3&#125;
0.476083472783 &#123;&#39;max_features&#39;: 4, &#39;n_estimators&#39;: 10&#125;
0.464671414883 &#123;&#39;max_features&#39;: 4, &#39;n_estimators&#39;: 30&#125;
0.500998128825 &#123;&#39;max_features&#39;: 6, &#39;n_estimators&#39;: 3&#125;
0.4723270942 &#123;&#39;max_features&#39;: 6, &#39;n_estimators&#39;: 10&#125;
0.464692668366 &#123;&#39;max_features&#39;: 6, &#39;n_estimators&#39;: 30&#125;
0.491656899488 &#123;&#39;max_features&#39;: 8, &#39;n_estimators&#39;: 3&#125;
0.468153614704 &#123;&#39;max_features&#39;: 8, &#39;n_estimators&#39;: 10&#125;
0.462619186958 &#123;&#39;max_features&#39;: 8, &#39;n_estimators&#39;: 30&#125;
0.534684910518 &#123;&#39;bootstrap&#39;: False, &#39;max_features&#39;: 2, &#39;n_estimators&#39;: 3&#125;
0.516588728861 &#123;&#39;bootstrap&#39;: False, &#39;max_features&#39;: 2, &#39;n_estimators&#39;: 10&#125;
0.535750828291 &#123;&#39;bootstrap&#39;: False, &#39;max_features&#39;: 3, &#39;n_estimators&#39;: 3&#125;
0.516586118116 &#123;&#39;bootstrap&#39;: False, &#39;max_features&#39;: 3, &#39;n_estimators&#39;: 10&#125;
0.535870542379 &#123;&#39;bootstrap&#39;: False, &#39;max_features&#39;: 4, &#39;n_estimators&#39;: 3&#125;
0.512291127875 &#123;&#39;bootstrap&#39;: False, &#39;max_features&#39;: 4, &#39;n_estimators&#39;: 10&#125;</code></pre>
<h3 id="随机参数搜索"><a href="#随机参数搜索" class="headerlink" title="随机参数搜索"></a>随机参数搜索</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> RandomizedSearchCV<br><span class="hljs-keyword">from</span> scipy.stats <span class="hljs-keyword">import</span> randint<br><br>param_distribs = &#123;<br>        <span class="hljs-string">&#x27;n_estimators&#x27;</span>: randint(low=<span class="hljs-number">1</span>, high=<span class="hljs-number">200</span>),<br>        <span class="hljs-string">&#x27;max_features&#x27;</span>: randint(low=<span class="hljs-number">1</span>, high=<span class="hljs-number">8</span>),<br>    &#125;<br><br>forest_reg = RandomForestRegressor(random_state=<span class="hljs-number">42</span>)<br>rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,<br>                                n_iter=<span class="hljs-number">10</span>, cv=<span class="hljs-number">5</span>, scoring=<span class="hljs-string">&#x27;neg_mean_squared_error&#x27;</span>, random_state=<span class="hljs-number">42</span>)<br>rnd_search.fit(titanic_prepared,titanic_label)<br></code></pre></td></tr></table></figure>



<pre><code>RandomizedSearchCV(cv=5, error_score=&#39;raise-deprecating&#39;,
          estimator=RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=None,
           max_features=&#39;auto&#39;, max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=&#39;warn&#39;, n_jobs=None,
           oob_score=False, random_state=42, verbose=0, warm_start=False),
          fit_params=None, iid=&#39;warn&#39;, n_iter=10, n_jobs=None,
          param_distributions=&#123;&#39;n_estimators&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D1B51B6198&gt;, &#39;max_features&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D1B51B6978&gt;&#125;,
          pre_dispatch=&#39;2*n_jobs&#39;, random_state=42, refit=True,
          return_train_score=&#39;warn&#39;, scoring=&#39;neg_mean_squared_error&#39;,
          verbose=0)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">cvres = rnd_search.cv_results_<br><span class="hljs-keyword">for</span> mean_score, params <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(cvres[<span class="hljs-string">&quot;mean_test_score&quot;</span>], cvres[<span class="hljs-string">&quot;params&quot;</span>]):<br>    print(np.sqrt(-mean_score), params)<br></code></pre></td></tr></table></figure>
<pre><code>0.464039645236 &#123;&#39;max_features&#39;: 7, &#39;n_estimators&#39;: 180&#125;
0.471855747311 &#123;&#39;max_features&#39;: 5, &#39;n_estimators&#39;: 15&#125;
0.469662076234 &#123;&#39;max_features&#39;: 3, &#39;n_estimators&#39;: 72&#125;
0.4681528737 &#123;&#39;max_features&#39;: 5, &#39;n_estimators&#39;: 21&#125;
0.464796324533 &#123;&#39;max_features&#39;: 7, &#39;n_estimators&#39;: 122&#125;
0.469440835097 &#123;&#39;max_features&#39;: 3, &#39;n_estimators&#39;: 75&#125;
0.469061926876 &#123;&#39;max_features&#39;: 3, &#39;n_estimators&#39;: 88&#125;
0.464095537716 &#123;&#39;max_features&#39;: 5, &#39;n_estimators&#39;: 100&#125;
0.465712273605 &#123;&#39;max_features&#39;: 3, &#39;n_estimators&#39;: 150&#125;
0.521753546174 &#123;&#39;max_features&#39;: 5, &#39;n_estimators&#39;: 2&#125;</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">feature_importances = grid_search.best_estimator_.feature_importances_<br>feature_importances<br></code></pre></td></tr></table></figure>



<pre><code>array([ 0.08056266,  0.35015732,  0.0670613 ,  0.052615  ,  0.39991869,
        0.01900031,  0.00781355,  0.02287116])</code></pre>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><ul>
<li>pipeline可以把训练模型这个过程也加进去</li>
<li>可以用sklearn的模块保存模型，加载模型</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">full_pipeline_with_predictor = Pipeline([<br>        (<span class="hljs-string">&quot;preparation&quot;</span>, full_pipeline),<br>        (<span class="hljs-string">&quot;linear&quot;</span>, LinearRegression())<br>    ])<br><br>full_pipeline_with_predictor.fit(titanic_data,titanic_label)<br>full_pipeline_with_predictor.predict(some_data)<br></code></pre></td></tr></table></figure>



<pre><code>array([ 0.14901183,  0.37719866,  0.18577842,  0.18589226,  0.29765968])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">my_model = full_pipeline_with_predictor<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.externals <span class="hljs-keyword">import</span> joblib<br>joblib.dump(my_model, <span class="hljs-string">&quot;my_model.pkl&quot;</span>) <span class="hljs-comment"># DIFF</span><br><span class="hljs-comment">#...</span><br>my_model_loaded = joblib.load(<span class="hljs-string">&quot;my_model.pkl&quot;</span>) <span class="hljs-comment"># DIFF</span><br></code></pre></td></tr></table></figure>
            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/">机器学习入门</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2019/04/09/%E8%AE%AD%E7%BB%83%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">训练线性模型</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>

<!-- SCRIPTS -->

  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.0/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.0/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js" ></script>






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    (function () {
      var path = "/local-search.xml";
      var inputArea = document.querySelector("#local-search-input");
      inputArea.onclick = function () {
        searchFunc(path, 'local-search-input', 'local-search-result');
        this.onclick = null
      }
    })()
  </script>















<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>



</body>
</html>
